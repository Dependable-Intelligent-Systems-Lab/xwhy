{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a id=\"top\"></a>\n# <div style=\"padding:20px;color:white;margin:0;font-size:35px;font-family:Georgia;text-align:left;display:fill;border-radius:5px;background-color:#254E58;overflow:hidden\"><b>Adversarial Attack on XWhy</b></div>\n\n<a id=\"1.2\"></a>\n<h2 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: #155D07; background-color: #ffffff;\"><b>Fooling</b> LIME and SHAP: Adversarial Attacks on Post hoc Explanation Methods</h2>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"text-align: justify;\">\"Fooling LIME and SHAP: Adversarial Attacks on Post hoc Explanation Methods\" refers to a research paper that examines the vulnerability of two popular post-hoc explanation methods, LIME (Local Interpretable Model-Agnostic Explanations) and SHAP (SHapley Additive exPlanations), to adversarial attacks. Adversarial attacks refer to malicious manipulations of input data designed to trick machine learning models into making incorrect predictions. In the context of explainable AI, the goal of these attacks is to modify the inputs in such a way that the explanation generated by the post-hoc explanation method is misleading.</p>\n    \n<p style=\"text-align: justify;\">The paper demonstrates that both LIME and SHAP are vulnerable to adversarial attacks and shows how attackers can manipulate the inputs to generate explanations that are inconsistent with the true behavior of the model. The findings of the paper highlight the importance of considering the robustness of post-hoc explanation methods to adversarial attacks when deploying these methods in security-sensitive applications. Overall, the results of the study suggest that while post-hoc explanation methods can provide valuable insights into the behavior of machine learning models, they should be used with caution and further research is needed to make them robust to adversarial attacks.</p>\n\n\nSource: [https://github.com/dylan-slack/Fooling-LIME-SHAP](https://github.com/dylan-slack/Fooling-LIME-SHAP)\n\nPaper: [Fooling LIME and SHAP: Adversarial Attacks on Post hoc Explanation Methods](https://arxiv.org/pdf/1911.02508.pdf)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"top\"></a>\n# <div style=\"padding:20px;color:white;margin:0;font-size:35px;font-family:Georgia;text-align:left;display:fill;border-radius:5px;background-color:#254E58;overflow:hidden\"><b>Table of content</b></div>\n\n<div style=\"background-color:aliceblue; padding:30px; font-size:15px;color:#034914\">\n    \n* [Import Libraries](#lib)\n* [COMPAS Example](#compas) \n* [Defining Racist Model](#racist)\n* [Defining XWhy Explainability Functions](#xwhy)\n* [Comparing XWhy with LIME and SHAP - Before Attack](#before_AA)\n* [Comparing XWhy with LIME and SHAP - Adversarial Attack](#AA)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"2\"></a>\n# <div style=\"padding:20px;color:white;margin:0;font-size:35px;font-family:Georgia;text-align:left;display:fill;border-radius:5px;background-color:#254E58;overflow:hidden\"><b>Import libraries</b></div>","metadata":{}},{"cell_type":"code","source":"from plotly.subplots import make_subplots\nimport plotly.graph_objects as go\nimport plotly.express as px\nimport matplotlib\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom  matplotlib.colors import LinearSegmentedColormap\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestClassifier\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2023-09-14T23:16:02.984735Z","iopub.execute_input":"2023-09-14T23:16:02.985091Z","iopub.status.idle":"2023-09-14T23:16:02.997094Z","shell.execute_reply.started":"2023-09-14T23:16:02.985055Z","shell.execute_reply":"2023-09-14T23:16:02.996107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/dylan-slack/Fooling-LIME-SHAP.git -quite","metadata":{"execution":{"iopub.status.busy":"2023-09-14T23:16:03.021273Z","iopub.execute_input":"2023-09-14T23:16:03.021656Z","iopub.status.idle":"2023-09-14T23:16:04.156102Z","shell.execute_reply.started":"2023-09-14T23:16:03.021605Z","shell.execute_reply":"2023-09-14T23:16:04.154841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.insert(1, '/kaggle/working/Fooling-LIME-SHAP')","metadata":{"execution":{"iopub.status.busy":"2023-09-14T23:16:04.158452Z","iopub.execute_input":"2023-09-14T23:16:04.158853Z","iopub.status.idle":"2023-09-14T23:16:04.167205Z","shell.execute_reply.started":"2023-09-14T23:16:04.158810Z","shell.execute_reply":"2023-09-14T23:16:04.165838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore') \n\nfrom adversarial_models import * \nfrom utils import *\nfrom get_data import *\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nimport numpy as np\nimport pandas as pd\n\nimport lime\nimport lime.lime_tabular\nimport shap\nfrom copy import deepcopy\n\nimport xgboost\nimport shap\n\nimport plotly.io as pio\n","metadata":{"execution":{"iopub.status.busy":"2023-09-14T23:16:04.169228Z","iopub.execute_input":"2023-09-14T23:16:04.169705Z","iopub.status.idle":"2023-09-14T23:16:04.180199Z","shell.execute_reply.started":"2023-09-14T23:16:04.169664Z","shell.execute_reply":"2023-09-14T23:16:04.178923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"compas\"></a>\n# <div style=\"padding:20px;color:white;margin:0;font-size:35px;font-family:Georgia;text-align:left;display:fill;border-radius:5px;background-color:#254E58;overflow:hidden\"><b>COMPAS Example</b></div>\n\n<p style=\"text-align: justify;\">The COMPAS Communities and Crime dataset is a popular dataset used in criminal justice research and machine learning studies. It contains information about defendants who have been charged with crimes in the US and their characteristics, including demographic information, criminal history, and the outcomes of their cases. The data was collected by the company Northpointe and is widely used to study the fairness and bias in risk assessment tools used in the criminal justice system. Despite its widespread use, the dataset has also been subject to controversy due to concerns over the accuracy of the data and the potential for algorithmic bias in the risk assessment scores used. Nevertheless, it remains an important resource for researchers and policymakers as they seek to better understand and address issues in the criminal justice system.</p>\n","metadata":{}},{"cell_type":"code","source":"def get_and_preprocess_compas_data(params):\n    \"\"\"Handle processing of COMPAS according to: https://github.com/propublica/compas-analysis\n\n    Parameters\n    ----------\n    params : Params\n    Returns\n    ----------\n    Pandas data frame X of processed data, np.ndarray y, and list of column names\n    \"\"\"\n    PROTECTED_CLASS = params.protected_class\n    UNPROTECTED_CLASS = params.unprotected_class\n    POSITIVE_OUTCOME = params.positive_outcome\n    NEGATIVE_OUTCOME = params.negative_outcome\n\n    compas_df = pd.read_csv(\"./Fooling-LIME-SHAP/data/compas-scores-two-years.csv\", index_col=0)\n    compas_df = compas_df.loc[(compas_df['days_b_screening_arrest'] <= 30) &\n                              (compas_df['days_b_screening_arrest'] >= -30) &\n                              (compas_df['is_recid'] != -1) &\n                              (compas_df['c_charge_degree'] != \"O\") &\n                              (compas_df['score_text'] != \"NA\")]\n\n    compas_df['length_of_stay'] = (\n                pd.to_datetime(compas_df['c_jail_out']) - pd.to_datetime(compas_df['c_jail_in'])).dt.days\n    X = compas_df[['age', 'two_year_recid', 'c_charge_degree', 'race', 'sex', 'priors_count', 'length_of_stay']]\n\n    # if person has high score give them the _negative_ model outcome\n    y = np.array([NEGATIVE_OUTCOME if score == 'High' else POSITIVE_OUTCOME for score in compas_df['score_text']])\n    sens = X.pop('race')\n\n    # assign African-American as the protected class\n    X = pd.get_dummies(X)\n    sensitive_attr = np.array(pd.get_dummies(sens).pop('African-American'))\n    X['race'] = sensitive_attr\n\n    # make sure everything is lining up\n    assert all((sens == 'African-American') == (X['race'] == PROTECTED_CLASS))\n    cols = [col for col in X]\n\n    return X, y, cols\n\n\ndef get_and_preprocess_cc(params):\n    \"\"\"\"Handle processing of Communities and Crime.  We exclude rows with missing values and predict\n    if the violent crime is in the 50th percentile.\n    Parameters\n    ----------\n    params : Params\n    Returns:\n    ----------\n    Pandas data frame X of processed data, np.ndarray y, and list of column names\n    \"\"\"\n    PROTECTED_CLASS = params.protected_class\n    UNPROTECTED_CLASS = params.unprotected_class\n    POSITIVE_OUTCOME = params.positive_outcome\n    NEGATIVE_OUTCOME = params.negative_outcome\n\n    X = pd.read_csv(\"./Fooling-LIME-SHAP/data/communities_and_crime_new_version.csv\", index_col=0)\n\n    # everything over 50th percentil gets negative outcome (lots of crime is bad)\n    high_violent_crimes_threshold = 50\n    y_col = 'ViolentCrimesPerPop numeric'\n\n    X = X[X[y_col] != \"?\"]\n    X[y_col] = X[y_col].values.astype('float32')\n\n    # just dump all x's that have missing values \n    cols_with_missing_values = []\n    for col in X:\n        if len(np.where(X[col].values == '?')[0]) >= 1:\n            cols_with_missing_values.append(col)\n\n    y = X[y_col]\n    y_cutoff = np.percentile(y, high_violent_crimes_threshold)\n    X = X.drop(\n        cols_with_missing_values + ['communityname string', 'fold numeric', 'county numeric', 'community numeric',\n                                    'state numeric'] + [y_col], axis=1)\n\n    # setup ys\n    cols = [c for c in X]\n    y = np.array([NEGATIVE_OUTCOME if val > y_cutoff else POSITIVE_OUTCOME for val in y])\n\n    return X, y, cols","metadata":{"execution":{"iopub.status.busy":"2023-09-14T23:16:04.182804Z","iopub.execute_input":"2023-09-14T23:16:04.183247Z","iopub.status.idle":"2023-09-14T23:16:04.207577Z","shell.execute_reply.started":"2023-09-14T23:16:04.183206Z","shell.execute_reply":"2023-09-14T23:16:04.206016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the data set and do some preprocessing\nparams = Params(\"./Fooling-LIME-SHAP/model_configurations/experiment_params.json\") \nnp.random.seed(params.seed)\nX, y, cols = get_and_preprocess_compas_data(params)\n\n# Add a random column -- this is what we'll have LIME/SHAP explain.\nX['unrelated_column'] = np.random.choice([0,1],size=X.shape[0])\nfeatures = [c for c in X]\n\ncategorical_feature_name = ['two_year_recid', 'c_charge_degree_F', 'c_charge_degree_M',\\\n                            'sex_Female', 'sex_Male', 'race', 'unrelated_column']\n\ncategorical_feature_indcs = [features.index(c) for c in categorical_feature_name]\n\nrace_indc = features.index('race')\nunrelated_indcs = features.index('unrelated_column')\nX = X.values","metadata":{"execution":{"iopub.status.busy":"2023-09-14T23:16:04.209705Z","iopub.execute_input":"2023-09-14T23:16:04.210161Z","iopub.status.idle":"2023-09-14T23:16:04.400693Z","shell.execute_reply.started":"2023-09-14T23:16:04.210113Z","shell.execute_reply":"2023-09-14T23:16:04.399685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"racist\"></a>\n# <div style=\"padding:20px;color:white;margin:0;font-size:35px;font-family:Georgia;text-align:left;display:fill;border-radius:5px;background-color:#254E58;overflow:hidden\"><b>Defining Racist Model</b></div>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"text-align: justify;\"> In the next step, we will define our model parameters `f` and `psi`. `f` is the main model that we will use to classify the data, while `psi` is the model that we want to use to explain the predictions made by `f`. In other words, `f` will make predictions about the data, and `psi` will help us understand and interpret those predictions. </p>\n\n<p style=\"text-align: justify;\">It's important to have both `f` and `psi` in our analysis, as `f` provides us with accurate predictions about the data, while `psi` helps us understand how the predictions were made and what factors were most important in making them. By having both models, we can make informed decisions based on the predictions made by `f`, while also understanding the reasoning behind them. This approach is useful in a variety of applications, including risk assessment, fraud detection, and predictive maintenance.</p>\n","metadata":{}},{"cell_type":"code","source":"class racist_model_f:\n    # Decision rule: classify negatively if race is black\n    def predict(self,X):\n        return np.array([params.negative_outcome if x[race_indc] > 0 else params.positive_outcome for x in X])\n\n    def predict_proba(self, X): \n        return one_hot_encode(self.predict(X))\n\n    def score(self, X,y):\n        return np.sum(self.predict(X)==y) / len(X)\n    \nclass innocuous_model_psi:\n    # Decision rule: classify according to randomly drawn column 'unrelated column'\n    def predict(self,X):\n        return np.array([params.negative_outcome if x[unrelated_indcs] > 0 else params.positive_outcome for x in X])\n\n    def predict_proba(self, X): \n        return one_hot_encode(self.predict(X))\n\n    def score(self, X,y):\n        return np.sum(self.predict(X)==y) / len(X)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T23:16:04.402739Z","iopub.execute_input":"2023-09-14T23:16:04.403118Z","iopub.status.idle":"2023-09-14T23:16:04.414822Z","shell.execute_reply.started":"2023-09-14T23:16:04.403081Z","shell.execute_reply":"2023-09-14T23:16:04.413492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split the data and normalize\nxtrain,xtest,ytrain,ytest = train_test_split(X,y)\nxtest_not_normalized = deepcopy(xtest)\nss = StandardScaler().fit(xtrain)\nxtrain = ss.transform(xtrain)\nxtest = ss.transform(xtest)\n\n# Train the adversarial model for LIME with f and psi \nadv_lime = Adversarial_Lime_Model(racist_model_f(), innocuous_model_psi()).\\\n            train(xtrain, ytrain, feature_names=features, categorical_features=categorical_feature_indcs)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T23:16:04.416634Z","iopub.execute_input":"2023-09-14T23:16:04.417173Z","iopub.status.idle":"2023-09-14T23:16:49.444477Z","shell.execute_reply.started":"2023-09-14T23:16:04.417131Z","shell.execute_reply":"2023-09-14T23:16:49.443230Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's just look at a the first example in the test set\nex_indc = np.random.choice(xtest.shape[0])\n\n# To get a baseline, we'll look at LIME applied to the biased model f\nnormal_explainer = lime.lime_tabular.LimeTabularExplainer(xtrain,feature_names=adv_lime.get_column_names(),\n                                                          discretize_continuous=False,\n                                                          categorical_features=categorical_feature_indcs)\n\nnormal_exp = normal_explainer.explain_instance(xtest[ex_indc], racist_model_f().predict_proba).as_list()\n\nprint (\"Explanation on biased f:\\n\",normal_exp[:3],\"\\n\\n\")\n\n# Now, lets look at the explanations on the adversarial model \nadv_explainer = lime.lime_tabular.LimeTabularExplainer(xtrain,feature_names=adv_lime.get_column_names(), \n                                                       discretize_continuous=False,\n                                                       categorical_features=categorical_feature_indcs)\n\nadv_exp = adv_explainer.explain_instance(xtest[ex_indc], adv_lime.predict_proba).as_list()\n\nprint (\"Explanation on adversarial model:\\n\",adv_exp[:3],\"\\n\")\n\nprint(\"Prediction fidelity: {0:3.2}\".format(adv_lime.fidelity(xtest[ex_indc:ex_indc+1])))","metadata":{"execution":{"iopub.status.busy":"2023-09-14T23:16:49.446661Z","iopub.execute_input":"2023-09-14T23:16:49.447131Z","iopub.status.idle":"2023-09-14T23:16:49.784547Z","shell.execute_reply.started":"2023-09-14T23:16:49.447079Z","shell.execute_reply":"2023-09-14T23:16:49.773802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the adversarial model for SHAP\nadv_shap = Adversarial_Kernel_SHAP_Model(racist_model_f(), innocuous_model_psi()).\\\n            train(xtrain, ytrain, feature_names=features)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T23:16:49.787189Z","iopub.execute_input":"2023-09-14T23:16:49.787889Z","iopub.status.idle":"2023-09-14T23:17:10.302054Z","shell.execute_reply.started":"2023-09-14T23:16:49.787822Z","shell.execute_reply":"2023-09-14T23:17:10.300826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the background distribution for the shap explainer using kmeans\nbackground_distribution = shap.kmeans(xtrain,10)\n\n# Let's use the shap kernel explainer and grab a point to explain\nto_examine = np.random.choice(xtest.shape[0])\n\n# Explain the biased model\nbiased_kernel_explainer = shap.KernelExplainer(racist_model_f().predict, background_distribution)\nbiased_shap_values = biased_kernel_explainer.shap_values(xtest[to_examine:to_examine+1])\n\n# Explain the adversarial model\nadv_kerenel_explainer = shap.KernelExplainer(adv_shap.predict, background_distribution)\nadv_shap_values = adv_kerenel_explainer.shap_values(xtest[to_examine:to_examine+1])\n\n# Plot it using SHAP's plotting features.\nshap.summary_plot(biased_shap_values, feature_names=features, plot_type=\"bar\")\nshap.summary_plot(adv_shap_values, feature_names=features, plot_type=\"bar\")\n\nprint (\"Fidelity: {0:3.2}\".format(adv_shap.fidelity(xtest[to_examine:to_examine+1])))","metadata":{"execution":{"iopub.status.busy":"2023-09-14T23:17:10.304813Z","iopub.execute_input":"2023-09-14T23:17:10.305199Z","iopub.status.idle":"2023-09-14T23:17:16.978613Z","shell.execute_reply.started":"2023-09-14T23:17:10.305162Z","shell.execute_reply":"2023-09-14T23:17:16.977520Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"xwhy\"></a>\n# <div style=\"padding:20px;color:white;margin:0;font-size:35px;font-family:Georgia;text-align:left;display:fill;border-radius:5px;background-color:#254E58;overflow:hidden\"><b>Defining XWhy Explainability Functions</b></div>","metadata":{}},{"cell_type":"code","source":"def Wasserstein_Dist(XX, YY):\n  \n    import numpy as np\n    nx = len(XX)\n    ny = len(YY)\n    n = nx + ny\n\n    XY = np.concatenate([XX,YY])\n    X2 = np.concatenate([np.repeat(1/nx, nx), np.repeat(0, ny)])\n    Y2 = np.concatenate([np.repeat(0, nx), np.repeat(1/ny, ny)])\n\n    S_Ind = np.argsort(XY)\n    XY_Sorted = XY[S_Ind]\n    X2_Sorted = X2[S_Ind]\n    Y2_Sorted = Y2[S_Ind]\n\n    Res = 0\n    E_CDF = 0\n    F_CDF = 0\n    power = 1\n\n    for ii in range(0, n-2):\n        E_CDF = E_CDF + X2_Sorted[ii]\n        F_CDF = F_CDF + Y2_Sorted[ii]\n        height = abs(F_CDF-E_CDF)\n        width = XY_Sorted[ii+1] - XY_Sorted[ii]\n        Res = Res + (height ** power) * width;  \n \n    return Res\n\ndef WasserstainLIME2(X_input, model, num_perturb = 500, L_num_perturb = 100, kernel_width2 = 0.75, epsilon = 0.1):\n    '''\n    WasserstainLIME is a statistical version of LIME (local interpretable model-agnostic explanations) \n    in which instead of Euclidean distance, the ECDF-based distance is used.\n    \n    X_input: should be a numpy array that represents one point in a n-dimensional space.\n    \n    num_perturb: Is the number of perturbations that the algorithm uses.\n    \n    L_num_perturb: Is the number of perturbations in the local areas that the algorithm uses.\n    \n    kernel_width: Is the Kernel Width. When the decision space is very dynamic, the kernel width should be low like 0.2, \n    otherwise kernel with around 0.75 would be ideal.\n    \n    model: It is the trained model that can be for a classification or regression. \n    \n    epsilon: It is used to normalize the WD values.\n    \n    '''\n    \n    X_input = (X_input - np.mean(X_input,axis=0)) / np.std(X_input,axis=0) #Standarization of data\n\n    X_lime = np.random.normal(0,1,size=(num_perturb,X_input.shape[0]))\n    \n    Xi2 = np.zeros((L_num_perturb,X_input.shape[0]))\n    \n    for jj in range(X_input.shape[0]):\n        Xi2[:,jj] = X_input[jj] + np.random.normal(0,0.05,L_num_perturb)\n\n    y_lime2  = np.zeros((num_perturb,1))\n    WD       = np.zeros((num_perturb,1))\n    weights2 = np.zeros((num_perturb,1))\n    \n    for ind, ii in enumerate(X_lime):\n        \n        df2 = pd.DataFrame()\n        \n        for jj in range(X_input.shape[0]):\n            temp1 = ii[jj] + np.random.normal(0,0.3,L_num_perturb)\n            df2[len(df2.columns)] = temp1\n\n        temp3 = model.predict(df2.to_numpy())\n#         print(temp3)\n\n        y_lime2[ind] = np.mean(temp3)  # For classification: np.argmax(np.bincount(temp3))\n        \n        WD1 = np.zeros((X_input.shape[0],1))\n        \n        df2 = df2.to_numpy()\n        \n        for kk in range(X_input.shape[0]):\n            #print( df2.shape)\n            WD1[kk] = Wasserstein_Dist(Xi2[:,kk], df2[:,kk])\n        \n        #print(WD1)\n        #print(ind)\n        WD[ind] = sum(WD1)\n        #print(WD)\n    \n        weights2[ind] = np.sqrt(np.exp(-((epsilon*WD[ind])**2)/(kernel_width2**2))) \n        #print(weights2[ind])\n        \n        del df2\n    \n    weights2 = weights2.flatten()\n    #print(weights2)\n    \n    simpler_model2 = LinearRegression() \n    simpler_model2.fit(X_lime, y_lime2, sample_weight=weights2)\n    y_linmodel2 = simpler_model2.predict(X_lime)\n    y_linmodel2 = y_linmodel2 < 0.5 #Conver to binary class\n    y_linmodel2 = y_linmodel2.flatten()\n    \n    return X_lime, y_lime2, weights2, y_linmodel2, simpler_model2.coef_.flatten()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T23:17:16.980333Z","iopub.execute_input":"2023-09-14T23:17:16.980710Z","iopub.status.idle":"2023-09-14T23:17:17.005037Z","shell.execute_reply.started":"2023-09-14T23:17:16.980676Z","shell.execute_reply":"2023-09-14T23:17:17.004017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def xwhy_tabular_wd(X_input, model, num_perturb = 500, L_num_perturb = 100, kernel_width2 = 0.75, epsilon = 0.1):\n    '''\n    WasserstainLIME is a statistical version of LIME (local interpretable model-agnostic explanations) \n    in which instead of Euclidean distance, the ECDF-based distance is used.\n    \n    X_input: should be a numpy array that represents one point in a n-dimensional space.\n    \n    num_perturb: Is the number of perturbations that the algorithm uses.\n    \n    L_num_perturb: Is the number of perturbations in the local areas that the algorithm uses.\n    \n    kernel_width: Is the Kernel Width. When the decision space is very dynamic, the kernel width should be low like 0.2, \n    otherwise kernel with around 0.75 would be ideal.\n    \n    model: It is the trained model that can be for a classification or regression. \n    \n    epsilon: It is used to normalize the WD values.\n    \n    '''\n    \n    X_input = (X_input - np.mean(X_input,axis=0)) / np.std(X_input,axis=0) #Standarization of data\n\n    X_lime = np.random.normal(0,1,size=(num_perturb,X_input.shape[0]))\n    \n    Xi2 = np.zeros((L_num_perturb,X_input.shape[0]))\n    \n    for jj in range(X_input.shape[0]):\n        Xi2[:,jj] = X_input[jj] + np.random.normal(0,0.001,L_num_perturb)\n\n    y_lime2  = np.zeros((num_perturb,1))\n    WD       = np.zeros((num_perturb,1))\n    weights2 = np.zeros((num_perturb,1))\n    \n    for ind, ii in enumerate(X_lime):\n        \n        df2 = pd.DataFrame()\n        \n        for jj in range(X_input.shape[0]):\n            temp1 = ii[jj] + np.random.normal(0,0.001,L_num_perturb)\n            df2[len(df2.columns)] = temp1\n\n        temp3 = model.predict(df2.to_numpy())\n#         print(temp3)\n\n        y_lime2[ind] = np.mean(temp3)  # For classification: np.argmax(np.bincount(temp3))\n        \n        WD1 = np.zeros((X_input.shape[0],1))\n        \n        df2 = df2.to_numpy()\n        \n        for kk in range(X_input.shape[0]):\n            #print( df2.shape)\n            WD1[kk] = Wasserstein_Dist(Xi2[:,kk], df2[:,kk])\n        \n        #print(WD1)\n        #print(ind)\n        WD[ind] = sum(WD1)\n        #print(WD)\n    \n        weights2[ind] = np.sqrt(np.exp(-((epsilon*WD[ind])**2)/(kernel_width2**2))) \n        #print(weights2[ind])\n        \n        del df2\n    \n    weights2 = weights2.flatten()\n    #print(weights2)\n    \n    simpler_model2 = LinearRegression() \n    simpler_model2.fit(X_lime, y_lime2, sample_weight=weights2)\n    y_linmodel2 = simpler_model2.predict(X_lime)\n    y_linmodel2 = y_linmodel2 < 0.5 #Conver to binary class\n    y_linmodel2 = y_linmodel2.flatten()\n    \n    return X_lime, y_lime2, weights2, y_linmodel2, simpler_model2.coef_.flatten()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T23:17:17.006707Z","iopub.execute_input":"2023-09-14T23:17:17.007270Z","iopub.status.idle":"2023-09-14T23:17:17.026711Z","shell.execute_reply.started":"2023-09-14T23:17:17.007216Z","shell.execute_reply":"2023-09-14T23:17:17.025348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nX_lime, y_lime2, weights2, y_linmodel2, WLIME_Coef1 = xwhy_tabular_wd(xtest[ex_indc].flatten(), \n                                                                      num_perturb = 10000, \n                                                                      kernel_width2 = 0.1, \n                                                                      L_num_perturb = 1,\n                                                                      model = racist_model_f(), \n                                                                      epsilon = 1.5)\n\n\n\ndf3 = pd.DataFrame()\ntemp0 = np.zeros((2,2))\n\nprint(WLIME_Coef1)\n\ndf3['WDL'] = WLIME_Coef1\ndf3['feature_names'] = features\n\nimport plotly.express as px\nfig = px.bar(df3, x='WDL', y='feature_names', orientation='h', color='feature_names')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T23:17:17.028172Z","iopub.execute_input":"2023-09-14T23:17:17.028756Z","iopub.status.idle":"2023-09-14T23:18:18.790443Z","shell.execute_reply.started":"2023-09-14T23:17:17.028696Z","shell.execute_reply":"2023-09-14T23:18:18.789652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nX_lime, y_lime2, weights2, y_linmodel2, WLIME_Coef2 = xwhy_tabular_wd(xtest[ex_indc].flatten(), \n                                                                      num_perturb = 1000, \n                                                                      kernel_width2 = 0.6, \n                                                                      L_num_perturb = 100,\n                                                                      model = adv_lime, \n                                                                      epsilon = 0.3)\nprint(WLIME_Coef2)\n\ndf3 = pd.DataFrame()\ntemp0 = np.zeros((2,2))\n\ndf3['WDL'] = WLIME_Coef2 \ndf3['feature_names'] = features\n\nimport plotly.express as px\nfig = px.bar(df3, x='WDL', y='feature_names', orientation='h', color='feature_names')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T23:18:18.791833Z","iopub.execute_input":"2023-09-14T23:18:18.792384Z","iopub.status.idle":"2023-09-14T23:18:46.710982Z","shell.execute_reply.started":"2023-09-14T23:18:18.792329Z","shell.execute_reply":"2023-09-14T23:18:46.709492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"before_AA\"></a>\n# <div style=\"padding:20px;color:white;margin:0;font-size:35px;font-family:Georgia;text-align:left;display:fill;border-radius:5px;background-color:#254E58;overflow:hidden\"><b>Comparing XWhy with LIME and SHAP - Before Attack</b></div>","metadata":{}},{"cell_type":"code","source":"xg_model = xgboost.XGBClassifier().fit(xtrain, ytrain)\n\nexplainer = shap.Explainer(xg_model)\nxg_shap_values = explainer(xtest[to_examine:to_examine+1])","metadata":{"execution":{"iopub.status.busy":"2023-09-14T23:18:46.712819Z","iopub.execute_input":"2023-09-14T23:18:46.713202Z","iopub.status.idle":"2023-09-14T23:18:47.605011Z","shell.execute_reply.started":"2023-09-14T23:18:46.713163Z","shell.execute_reply":"2023-09-14T23:18:47.603975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_lime, y_lime2, weights2, y_linmodel2, WLIME_Coef_xg = xwhy_tabular_wd(xtest[ex_indc].flatten(), \n                                                                      num_perturb = 5000, \n                                                                      kernel_width2 = 0.75, \n                                                                      L_num_perturb = 10,\n                                                                      model = xg_model, \n                                                                      epsilon = 0.3)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T23:18:47.606785Z","iopub.execute_input":"2023-09-14T23:18:47.607445Z","iopub.status.idle":"2023-09-14T23:19:45.658220Z","shell.execute_reply.started":"2023-09-14T23:18:47.607370Z","shell.execute_reply":"2023-09-14T23:19:45.656589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LIME_xg = lime.lime_tabular.LimeTabularExplainer(xtrain,feature_names=adv_lime.get_column_names(),\n                                                          discretize_continuous=False,\n                                                          categorical_features=categorical_feature_indcs)\n\nLIME_xg_exp = normal_explainer.explain_instance(xtest[ex_indc], xg_model.predict_proba).as_list()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T23:19:45.660361Z","iopub.execute_input":"2023-09-14T23:19:45.661263Z","iopub.status.idle":"2023-09-14T23:19:45.800879Z","shell.execute_reply.started":"2023-09-14T23:19:45.661208Z","shell.execute_reply":"2023-09-14T23:19:45.799794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lime_features = ['priors_count', 'c_charge_degree_F','two_year_recid','sex_Male','length_of_stay','age','c_charge_degree_M','unrelated_column','sex_Female','race']\n\nLIME_xg_exp\nexp4 = []\nfor ii, jj in LIME_xg_exp:\n    exp4.append(jj)\nexp_simple = exp4[::-1]","metadata":{"execution":{"iopub.status.busy":"2023-09-14T23:19:45.802045Z","iopub.execute_input":"2023-09-14T23:19:45.802378Z","iopub.status.idle":"2023-09-14T23:19:45.814483Z","shell.execute_reply.started":"2023-09-14T23:19:45.802344Z","shell.execute_reply":"2023-09-14T23:19:45.813084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -U kaleido -q","metadata":{"execution":{"iopub.status.busy":"2023-09-14T23:19:45.820122Z","iopub.execute_input":"2023-09-14T23:19:45.821844Z","iopub.status.idle":"2023-09-14T23:19:55.116596Z","shell.execute_reply.started":"2023-09-14T23:19:45.821776Z","shell.execute_reply":"2023-09-14T23:19:55.115028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = make_subplots(rows=1, cols=3,\n                    subplot_titles=(\"SMILE\",\"SHAP\",\"LIME\"),\n                    horizontal_spacing = 0.1)\n\nfig.add_trace(\n    go.Bar(x=WLIME_Coef_xg, y=features, orientation='h', \n           marker=dict(color=np.argsort(WLIME_Coef1), coloraxis=\"coloraxis\")),#, color=df3['feature_names']),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Bar(x=xg_shap_values[0].values, y=features, orientation='h', \n           marker=dict(color=np.argsort(xg_shap_values[0].values), coloraxis=\"coloraxis\")),\n    row=1, col=2\n)\n\nfig.add_trace(\n    go.Bar(x=exp_simple, y=lime_features, orientation='h', \n           marker=dict(color=np.argsort(exp_simple), coloraxis=\"coloraxis\")),\n    row=1, col=3\n)\n\nfig.update_layout(height=600, width=1500, title_text=\"Comparing SHAP, LIME and SMILE without Adversarial Attack on COMPAS Dataset\",\n                  coloraxis=dict(colorscale='Bluered_r'), showlegend=False) # px.colors.sequential.Viridis\nfig.show()\n\n# fig.write_image(\"images/before_AA.png\")","metadata":{"execution":{"iopub.status.busy":"2023-09-14T23:19:55.118959Z","iopub.execute_input":"2023-09-14T23:19:55.119365Z","iopub.status.idle":"2023-09-14T23:19:55.212035Z","shell.execute_reply.started":"2023-09-14T23:19:55.119321Z","shell.execute_reply":"2023-09-14T23:19:55.210702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"AA\"></a>\n# <div style=\"padding:20px;color:white;margin:0;font-size:35px;font-family:Georgia;text-align:left;display:fill;border-radius:5px;background-color:#254E58;overflow:hidden\"><b>Comparing XWhy with LIME and SHAP - After Adversarial Attack</b></div>","metadata":{}},{"cell_type":"code","source":"adv_shap_values[0]\n\nnormal_exp\nexp4 = []\nfor ii, jj in normal_exp:\n    exp4.append(jj)\nexp_racist = exp4[::-1]\nexp_racist\n\nfig = make_subplots(rows=1, cols=3,\n                    subplot_titles=(\"SMILE\",\"SHAP\",\"LIME\"),\n                    horizontal_spacing = 0.1)\n\nfig.add_trace(\n    go.Bar(x=WLIME_Coef1, y=features, orientation='h', \n           marker=dict(color=np.argsort(WLIME_Coef1), coloraxis=\"coloraxis\")),#, color=df3['feature_names']),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Bar(x=biased_shap_values[0], y=features, orientation='h', \n           marker=dict(color=np.argsort(biased_shap_values[0]), coloraxis=\"coloraxis\")),\n    row=1, col=2\n)\n\nfig.add_trace(\n    go.Bar(x=exp_racist, y=lime_features, orientation='h', \n           marker=dict(color=np.argsort(exp_racist), coloraxis=\"coloraxis\")),\n    row=1, col=3\n)\n\nfig.update_layout(height=600, width=1500, title_text=\"Comparing SHAP, LIME and SMILE for A Racist Model\",\n                  coloraxis=dict(colorscale='Bluered_r'), showlegend=False) # px.colors.sequential.Viridis\n\nfig.update_layout(\n    title=dict(\n        text=(\"Comparing SHAP, LIME and SMILE for A Racist Model\"),\n        font=dict(\n            family=\"Courier New Bold, monospace\",\n            size=22,\n            color=\"RebeccaPurple\"\n        )\n    ),\n    xaxis=dict(\n        tickfont=dict(\n            family=\"Courier New Bold, monospace\",\n            size=22,\n            color=\"RebeccaPurple\"\n        )\n    ),\n    xaxis2=dict(\n        tickfont=dict(\n            family=\"Courier New Bold, monospace\",\n            size=22,\n            color=\"RebeccaPurple\"\n        )\n    ),\n    xaxis3=dict(\n        tickfont=dict(\n            family=\"Courier New Bold, monospace\",\n            size=22,\n            color=\"RebeccaPurple\"\n        )\n    ),\n    coloraxis=dict(colorscale='Bluered_r'),\n    showlegend=False\n)\n\nfig.show()\n\n# fig.write_image(\"images/Racist.png\")","metadata":{"execution":{"iopub.status.busy":"2023-09-14T23:19:55.214057Z","iopub.execute_input":"2023-09-14T23:19:55.214808Z","iopub.status.idle":"2023-09-14T23:19:55.307017Z","shell.execute_reply.started":"2023-09-14T23:19:55.214752Z","shell.execute_reply":"2023-09-14T23:19:55.305771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# adv_exp\nexp3 = []\nfor ii, jj in adv_exp:\n    exp3.append(jj)\nexp_adv = exp3[::-1]\nexp_adv\n\nfig = make_subplots(rows=1, cols=3,\n                    subplot_titles=(\"SMILE\",\"SHAP\",\"LIME\"),\n                    horizontal_spacing = 0.1)\n\nfig.add_trace(\n    go.Bar(x=WLIME_Coef2, y=features, orientation='h', \n           marker=dict(color=np.argsort(WLIME_Coef2), coloraxis=\"coloraxis\")),#, color=df3['feature_names']),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Bar(x=np.array(adv_shap_values[0]), y=features, orientation='h', \n           marker=dict(color=np.argsort(adv_shap_values[0]), coloraxis=\"coloraxis\")),\n    row=1, col=2\n)\n\nfig.add_trace(\n    go.Bar(x=exp_adv, y=features, orientation='h', \n           marker=dict(color=np.argsort(exp_adv), coloraxis=\"coloraxis\")),\n    row=1, col=3\n)\n\nfig.update_layout(height=600, width=1500, title_text=\"Comparing SHAP, LIME and SMILE against Adversarial Attack - Unrealated Feature\",\n                  coloraxis=dict(colorscale='Bluered_r'), showlegend=False) # px.colors.sequential.Viridis\n\n\nfig.update_layout(\n    title=dict(\n        text=\"Comparing SHAP, LIME and SMILE against Adversarial Attack - Unrealated Feature\",\n        font=dict(\n            family=\"Courier New Bold, monospace\",\n            size=22,\n            color=\"RebeccaPurple\"\n        )\n    ),\n    xaxis=dict(\n        tickfont=dict(\n            family=\"Courier New Bold, monospace\",\n            size=22,\n            color=\"RebeccaPurple\"\n        )\n    ),\n    xaxis2=dict(\n        tickfont=dict(\n            family=\"Courier New Bold, monospace\",\n            size=22,\n            color=\"RebeccaPurple\"\n        )\n    ),\n    xaxis3=dict(\n        tickfont=dict(\n            family=\"Courier New Bold, monospace\",\n            size=22,\n            color=\"RebeccaPurple\"\n        )\n    ),\n    coloraxis=dict(colorscale='Bluered_r'),\n    showlegend=False\n)\n\nfig.show()\n\n# fig.write_image(\"images/Unrealated.png\")","metadata":{"execution":{"iopub.status.busy":"2023-09-14T23:19:55.315044Z","iopub.execute_input":"2023-09-14T23:19:55.315418Z","iopub.status.idle":"2023-09-14T23:19:55.407869Z","shell.execute_reply.started":"2023-09-14T23:19:55.315387Z","shell.execute_reply":"2023-09-14T23:19:55.406656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"index_unrelated = features.index(\"unrelated_column\")\n\n# Calculate the summation of the values of \"Unrelated_Column\" for the three parameters\nsum_unrelated = WLIME_Coef2[index_unrelated] + adv_shap_values[0][index_unrelated] + exp_adv[index_unrelated]\n\n# Update the values in the three data arrays at the identified index\nprint(np.abs(WLIME_Coef2[index_unrelated]) / sum(np.abs(WLIME_Coef2)))\nprint(np.abs(adv_shap_values[0][index_unrelated]) / sum(np.abs(adv_shap_values[0])))\nprint(np.abs(exp_adv[index_unrelated]) / sum(np.abs(exp_adv)))","metadata":{"execution":{"iopub.status.busy":"2023-09-14T23:24:12.402337Z","iopub.execute_input":"2023-09-14T23:24:12.402815Z","iopub.status.idle":"2023-09-14T23:24:12.412324Z","shell.execute_reply.started":"2023-09-14T23:24:12.402778Z","shell.execute_reply":"2023-09-14T23:24:12.411343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<center> <a href=\"#top\" role=\"button\" aria-pressed=\"true\" >‚¨ÜÔ∏èBack to Table of Contents ‚¨ÜÔ∏è</a>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"border-radius:10px;border:#034914 solid;padding: 15px;background-color:aliceblue;font-size:90%;text-align:left\">\n\n<h4><b>Author :</b> Koorosh Aslansefat </h4>\n\n<h4> <b>Some information:</b> </h4>\n\n<b>üëâCheck my Kaggle Notebooks :</b> https://www.kaggle.com/kooaslansefat <br>\n<b>üëâContact Me :</b> <a href=\"mailto:koo.ec2008@gmail.com\">koo.ec2008@gmail.com</a><br>\n<b>üëâFind me LinkedIn :</b> www.linkedin.com/in/koorosh-aslansefat <br>\n<b>üëâFind me Github :</b> https://github.com/koo-ec <br>\n    \n    \n<center> <strong> If you liked this Notebook, please do upvote. </strong>\n    \n<center> <strong> If you have any questions, feel free to contact me! </strong>\n    \n<center> <strong> ‚ú®Best Wishes‚ú® </strong>","metadata":{}},{"cell_type":"markdown","source":"<center> <img src=\"https://raw.githubusercontent.com/ntclai/PictureForMyProject/main/87481-of-thanks-letter-text-logo-calligraphy-drawing%20(1).png\" style='width: 600px; height: 300px;'>","metadata":{}}]}