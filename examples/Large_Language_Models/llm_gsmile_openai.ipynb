{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"top\"></a>\n",
        "# <div style=\"padding:20px;color:white;margin:0;font-size:35px;font-family:Georgia;text-align:center;display:fill;border-radius:5px;background-color:#003d99;overflow:hidden\"><b>Explaining Language Models using SMILE </b></div>"
      ],
      "metadata": {
        "id": "W2IDURjtAUaW"
      },
      "id": "W2IDURjtAUaW"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Large language models like GPT, LLAMA, and Claude have become incredibly powerful at generating text, but they are still black boxes, so it is hard to understand how they decide what to say. That lack of transparency can be problematic, especially in fields where trust and accountability matter. To help with this, we introduce SMILE, a new method that explains how these models respond to different parts of a prompt. SMILE is model-agnostic and works by slightly changing the input, measuring how the output changes, and then highlighting which words had the most impact. Create simple visual heat maps showing which parts of a prompt matter the most. We tested SMILE on several leading LLMs and used metrics such as accuracy, consistency, stability, and fidelity to show that it gives clear and reliable explanations. By making these models easier to understand, SMILE brings us one step closer to making AI more transparent and trustworthy.\n",
        "\n",
        "In this notebook, we apply SMILE to GPT-3.5 using the sentence: \"What is the meaning of life?\" to demonstrate its effectiveness."
      ],
      "metadata": {
        "id": "hSqC7gQPAby6"
      },
      "id": "hSqC7gQPAby6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <div style=\"padding:20px;color:white;margin:0;font-size:35px;font-family:Georgia;text-align:center;display:fill;border-radius:5px;background-color:#003d99;overflow:hidden\"><b>Required Libraries</b></div>"
      ],
      "metadata": {
        "id": "vs-QHQy9Ah-e"
      },
      "id": "vs-QHQy9Ah-e"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "q9vunxECAXYb",
      "metadata": {
        "id": "q9vunxECAXYb"
      },
      "outputs": [],
      "source": [
        "# !pip install -q openai~=2.8.1 sentence-transformers~=5.1.2 pot~=0.9.6 scipy~=1.16.3 matplotlib~=3.10.0 gensim~=4.4.0 scikit-learn~=1.6.1 numpy~=2.0.2 pandas~=2.2.2 python-dotenv~=1.2.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "eacaeec6",
      "metadata": {
        "id": "eacaeec6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95a81a86-507b-47d3-f3d2-352f7a74d881"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.2/40.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Installation\n",
        "%pip install -q openai~=2.8.1 numpy~=2.0.2 matplotlib~=3.10.0 scikit-learn~=1.6.1 gensim~=4.4.0 pot~=0.9.6 python-dotenv~=1.2.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import logging\n",
        "\n",
        "from openai import OpenAI\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import transforms\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import gensim.downloader as api\n",
        "from gensim.models import KeyedVectors\n",
        "from dotenv import load_dotenv"
      ],
      "metadata": {
        "id": "Fsz3m1oI73s8"
      },
      "id": "Fsz3m1oI73s8",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configure logger"
      ],
      "metadata": {
        "id": "vvxLMPecs1ck"
      },
      "id": "vvxLMPecs1ck"
    },
    {
      "cell_type": "code",
      "source": [
        "logger = logging.getLogger(__name__)\n",
        "logger.setLevel(logging.INFO)"
      ],
      "metadata": {
        "id": "Aha_WmQzsxCn"
      },
      "id": "Aha_WmQzsxCn",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Env vars"
      ],
      "metadata": {
        "id": "jPzcxoeos2VQ"
      },
      "id": "jPzcxoeos2VQ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load OpenAI API key\n",
        "load_dotenv()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnkxO9ous36V",
        "outputId": "0926242f-cf8b-44cc-e322-65295fae7e3f"
      },
      "id": "tnkxO9ous36V",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"top\"></a>\n",
        "# <div style=\"padding:20px;color:white;margin:0;font-size:35px;font-family:Georgia;text-align:center;display:fill;border-radius:5px;background-color:#003d99;overflow:hidden\"><b>GPT interaction</b></div>"
      ],
      "metadata": {
        "id": "-WCTZd_Bs6C3"
      },
      "id": "-WCTZd_Bs6C3"
    },
    {
      "cell_type": "code",
      "source": [
        "def gpt_answer(\n",
        "    client: OpenAI,\n",
        "    prompt: str,\n",
        "    model: str = \"gpt-3.5-turbo-instruct\",\n",
        "    max_tokens: int = 200,\n",
        "    temperature: float = 0.0\n",
        ") -> str:\n",
        "    \"\"\"Generate a full natural-language GPT answer.\n",
        "\n",
        "    Supports both instruct-style models (using completions) and\n",
        "    reasoning models (using responses.create).\n",
        "\n",
        "    Args:\n",
        "        client (OpenAI): OpenAI client instance.\n",
        "        prompt (str): The input prompt.\n",
        "        model (str): Model name.\n",
        "        max_tokens (int): Maximum output token count.\n",
        "        temperature (float): Sampling temperature (ignored for\n",
        "            reasoning models).\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text output. Returns an empty string on\n",
        "            error.\n",
        "    \"\"\"\n",
        "    is_reasoning = model.startswith((\"o1\", \"o3\", \"o4\", \"gpt-5\"))\n",
        "\n",
        "    try:\n",
        "        if is_reasoning:\n",
        "            # Reasoning models use responses.create\n",
        "            resp = client.responses.create(\n",
        "                model=model,\n",
        "                input=prompt,\n",
        "                max_output_tokens=max_tokens,\n",
        "                reasoning_effort=\"low\"\n",
        "            )\n",
        "            return resp.output_text.strip()\n",
        "\n",
        "        # Instruct-type models use completions.create\n",
        "        resp = client.completions.create(\n",
        "            model=model,\n",
        "            prompt=prompt,\n",
        "            max_tokens=max_tokens,\n",
        "            temperature=temperature\n",
        "        )\n",
        "        return resp.choices[0].text.strip()\n",
        "\n",
        "    except Exception as exc:\n",
        "        logger.error(\"GPT answer error: %s\", exc)\n",
        "        return \"\"\n",
        "\n",
        "\n",
        "def gpt_score(\n",
        "    client: OpenAI,\n",
        "    prompt: str,\n",
        "    model: str = \"gpt-3.5-turbo-instruct\",\n",
        "    max_tokens: int = 10,\n",
        "    temperature: float = 0.0\n",
        ") -> str:\n",
        "    \"\"\"Request GPT to return a single numeric score.\n",
        "\n",
        "    Automatically handles both instruct models and reasoning models.\n",
        "    For reasoning models, temperature is disabled and the call is\n",
        "    routed through responses.create.\n",
        "\n",
        "    Args:\n",
        "        client (OpenAI): OpenAI client instance.\n",
        "        prompt (str): The prompt containing the scoring instruction.\n",
        "        model (str): Model name.\n",
        "        max_tokens (int): Maximum tokens for the numeric output.\n",
        "        temperature (float): Sampling temperature (ignored for\n",
        "            reasoning models).\n",
        "\n",
        "    Returns:\n",
        "        str: The numeric score as text. Returns \"0\" on error.\n",
        "    \"\"\"\n",
        "    is_reasoning = model.startswith((\"o1\", \"o3\", \"o4\", \"gpt-5\"))\n",
        "\n",
        "    final_prompt = (\n",
        "        prompt + \"\\nRespond with a single number only. No explanation.\"\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        if is_reasoning:\n",
        "            resp = client.responses.create(\n",
        "                model=model,\n",
        "                input=final_prompt,\n",
        "                max_output_tokens=max_tokens,\n",
        "                reasoning_effort=\"low\"\n",
        "            )\n",
        "            return resp.output_text.strip()\n",
        "\n",
        "        resp = client.completions.create(\n",
        "            model=model,\n",
        "            prompt=final_prompt,\n",
        "            max_tokens=max_tokens,\n",
        "            temperature=temperature\n",
        "        )\n",
        "        return resp.choices[0].text.strip()\n",
        "\n",
        "    except Exception as exc:\n",
        "        logger.error(\"GPT score error: %s\", exc)\n",
        "        return \"0\""
      ],
      "metadata": {
        "id": "Sf6Ag9gPs8D8"
      },
      "id": "Sf6Ag9gPs8D8",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"top\"></a>\n",
        "# <div style=\"padding:20px;color:white;margin:0;font-size:35px;font-family:Georgia;text-align:center;display:fill;border-radius:5px;background-color:#003d99;overflow:hidden\"><b> Prompt Perturbation and GPT Response Analysis</b></div>"
      ],
      "metadata": {
        "id": "IFgGMAB8s_Z9"
      },
      "id": "IFgGMAB8s_Z9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We generate 64 random perturbations of the original prompt by selectively including or excluding words. Each perturbed prompt is sent to GPT-3.5-turbo, and the resulting one-word outputs are collected.\n",
        "\n",
        "This helps analyze the model’s sensitivity to different input combinations and prepares data for attribution scoring."
      ],
      "metadata": {
        "id": "tz4TkisvA6EH"
      },
      "id": "tz4TkisvA6EH"
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_binary_mask(\n",
        "    text_list: list[str],\n",
        "    mask: tuple[int, ...],\n",
        "    rng: np.random.Generator\n",
        ") -> list[str]:\n",
        "    \"\"\"Apply a binary mask to a list of words and ensure minimum word count.\n",
        "\n",
        "    The mask selects words where a `1` indicates inclusion. If the mask\n",
        "    includes fewer than two valid words, additional random words from the\n",
        "    original text are added to preserve semantic stability.\n",
        "\n",
        "    Args:\n",
        "        text_list (list[str]): Tokenized original text.\n",
        "        mask (tuple[int, ...]): Binary mask indicating selected words.\n",
        "        rng (np.random.Generator): Random generator for selecting fallback\n",
        "            words.\n",
        "\n",
        "    Returns:\n",
        "        list[str]: The perturbed list of words.\n",
        "    \"\"\"\n",
        "    selected = [\n",
        "        w for w, flag in zip(text_list, mask)\n",
        "        if flag == 1 and w.strip() != \"\"\n",
        "    ]\n",
        "\n",
        "    if len(selected) < 2:\n",
        "        needed = 2 - len(selected)\n",
        "        candidates = [w for w in text_list if w.strip() != \"\"]\n",
        "        extra = rng.choice(candidates, needed, replace=False)\n",
        "        result = list(set(selected + list(extra)))\n",
        "    else:\n",
        "        result = list(set(selected))\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def generate_perturbations(\n",
        "    text: str,\n",
        "    num_perturb: int = 64,\n",
        "    seed: int = 1024\n",
        ") -> tuple[list[str], list[tuple]]:\n",
        "    \"\"\"Generate unique binary perturbations and perturbed text versions.\n",
        "\n",
        "    Args:\n",
        "        text (str): Original input text.\n",
        "        num_perturb (int): Number of perturbations to generate.\n",
        "        seed (int): Random seed for reproducibility.\n",
        "\n",
        "    Returns:\n",
        "        tuple[list[str], list[tuple]]:\n",
        "            - List of perturbed texts (Responses)\n",
        "            - List of binary perturbation vectors (Perturbations)\n",
        "    \"\"\"\n",
        "    words = text.split()\n",
        "    text_list = words.copy()\n",
        "    num_words = len(words)\n",
        "\n",
        "    rng = np.random.default_rng(seed)\n",
        "\n",
        "    responses = []\n",
        "    perturbations = []\n",
        "    unique_perturbations = set()\n",
        "\n",
        "    attempts = 0\n",
        "    max_attempts = num_perturb * 10\n",
        "\n",
        "    # Loop for unique perturbations only\n",
        "    while len(unique_perturbations) < num_perturb and attempts < max_attempts:\n",
        "        p = tuple(rng.binomial(1, 0.5, size=num_words))\n",
        "\n",
        "        if p not in unique_perturbations and sum(p) > 0:\n",
        "            unique_perturbations.add(p)\n",
        "            perturbed_txt = apply_binary_mask(text_list, p, rng)\n",
        "            corpus = \" \".join(perturbed_txt)\n",
        "\n",
        "            responses.append(corpus)\n",
        "            perturbations.append(p)\n",
        "\n",
        "            logger.info(\n",
        "                \"Perturbation: %s, Perturbed Text: %s\", p, corpus\n",
        "            )\n",
        "\n",
        "        attempts += 1\n",
        "\n",
        "    # If more perturbations are needed, allow repeats by sampling\n",
        "    # from unique_perturbations\n",
        "    while len(responses) < num_perturb:\n",
        "        p = rng.choice(list(unique_perturbations))\n",
        "        perturbed_txt = apply_binary_mask(text_list, p, rng)\n",
        "        corpus = \" \".join(perturbed_txt)\n",
        "\n",
        "        responses.append(corpus)\n",
        "        perturbations.append(p)\n",
        "\n",
        "        logger.info(\n",
        "            \"Perturbation (reused): %s, Perturbed Text: %s\", p, corpus\n",
        "        )\n",
        "\n",
        "    return responses, perturbations\n",
        "\n",
        "\n",
        "def query_gpt_for_perturbations(\n",
        "        client,\n",
        "        model: str,\n",
        "        responses: list[str],\n",
        "        max_tokens: int = 10,\n",
        "        temperature: float = 0.0\n",
        ") -> list[tuple[str, str]]:\n",
        "    \"\"\"Query GPT for each perturbed text and return (input, output) pairs.\n",
        "\n",
        "    Args:\n",
        "        client: OpenAI client instance.\n",
        "        model (str): GPT model name.\n",
        "        responses (list[str]): Perturbed text inputs.\n",
        "        max_tokens (int): Max tokens for GPT response.\n",
        "        temperature (float): Sampling temperature.\n",
        "\n",
        "    Returns:\n",
        "        list[tuple[str, str]]: List of (perturbed_input, gpt_output).\n",
        "    \"\"\"\n",
        "    gpt_outputs = []\n",
        "\n",
        "    for text in responses:\n",
        "        logger.info(\"Querying GPT with perturbed text: %s\", text)\n",
        "\n",
        "        gpt_resp = gpt_score(\n",
        "            client=client,\n",
        "            prompt=text,\n",
        "            model=model,\n",
        "            max_tokens=max_tokens,\n",
        "            temperature=temperature\n",
        "        )\n",
        "\n",
        "        gpt_outputs.append((text, gpt_resp))\n",
        "\n",
        "    for i, (inp, out) in enumerate(gpt_outputs, 1):\n",
        "        logger.info(\"Perturbation %d:\", i)\n",
        "        logger.info(\"Input: %s\", inp)\n",
        "        logger.info(\"GPT Output: %s\", out)\n",
        "        logger.info(\"-\" * 50)\n",
        "\n",
        "    return gpt_outputs\n"
      ],
      "metadata": {
        "id": "nvQUkx1KtBK5"
      },
      "id": "nvQUkx1KtBK5",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word2Vec model"
      ],
      "metadata": {
        "id": "1F8EVjNTtG8v"
      },
      "id": "1F8EVjNTtG8v"
    },
    {
      "cell_type": "code",
      "source": [
        "def load_google_news_vectors():\n",
        "    # First try gensim downloader (fastest & simplest)\n",
        "    try:\n",
        "        print(\"Trying to load 'word2vec-google-news-300' via gensim.api...\")\n",
        "        return api.load(\"word2vec-google-news-300\")\n",
        "    except Exception:\n",
        "        print(\"Gensim API unavailable — downloading manually...\")\n",
        "\n",
        "    # Manual fallback (public mirror)\n",
        "    url = \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\"\n",
        "    local_path = \"GoogleNews-vectors-negative300.bin.gz\"\n",
        "    extracted_path = \"GoogleNews-vectors-negative300.bin\"\n",
        "\n",
        "    # Download if missing\n",
        "    if not os.path.exists(local_path):\n",
        "        import urllib.request\n",
        "        print(\"Downloading GoogleNews vectors...\")\n",
        "        urllib.request.urlretrieve(url, local_path)\n",
        "\n",
        "    # Extract if needed\n",
        "    if not os.path.exists(extracted_path):\n",
        "        import gzip\n",
        "        import shutil\n",
        "        print(\"Extracting .gz file...\")\n",
        "        with gzip.open(local_path, \"rb\") as f_in:\n",
        "            with open(extracted_path, \"wb\") as f_out:\n",
        "                shutil.copyfileobj(f_in, f_out)\n",
        "\n",
        "    print(\"Loading Word2Vec model...\")\n",
        "    return KeyedVectors.load_word2vec_format(extracted_path, binary=True)"
      ],
      "metadata": {
        "id": "XwGFIb8UtI3A"
      },
      "id": "XwGFIb8UtI3A",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text utilities"
      ],
      "metadata": {
        "id": "P4PSdUxLtLlQ"
      },
      "id": "P4PSdUxLtLlQ"
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text: str) -> str:\n",
        "    \"\"\"Clean text by removing punctuation, lowering, and stripping whitespace.\n",
        "\n",
        "    Args:\n",
        "        text (str): Input text.\n",
        "\n",
        "    Returns:\n",
        "        str: Cleaned text.\n",
        "    \"\"\"\n",
        "    cleaned = re.sub(r\"[^\\w\\s]\", \"\", text.lower())\n",
        "    return cleaned.strip()\n",
        "\n",
        "\n",
        "def safe_wmdistance(model, text1: str, text2: str) -> float:\n",
        "    \"\"\"Compute Word Mover's Distance using only in-vocabulary cleaned words.\n",
        "\n",
        "    Args:\n",
        "        model: Word2Vec model with wmdistance().\n",
        "        text1 (str): First text.\n",
        "        text2 (str): Second text.\n",
        "\n",
        "    Returns:\n",
        "        float: WMD distance or 1.0 if texts have no valid tokens.\n",
        "    \"\"\"\n",
        "    words1 = [w for w in clean_text(text1).split() if w in model]\n",
        "    words2 = [w for w in clean_text(text2).split() if w in model]\n",
        "    if not words1 or not words2:\n",
        "        return 1.0\n",
        "    return model.wmdistance(words1, words2)"
      ],
      "metadata": {
        "id": "F_QirGRktNE1"
      },
      "id": "F_QirGRktNE1",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"top\"></a>\n",
        "# <div style=\"padding:20px;color:white;margin:0;font-size:35px;font-family:Georgia;text-align:center;display:fill;border-radius:5px;background-color:#003d99;overflow:hidden\"><b>Compute Distances & Semantic Similarity Using Word Mover’s Distance (WMD)</b></div>"
      ],
      "metadata": {
        "id": "BBPX57yItUcz"
      },
      "id": "BBPX57yItUcz"
    },
    {
      "cell_type": "markdown",
      "source": [
        "To quantify how semantically different each GPT-generated output is from the original response, we use the Word Mover’s Distance (WMD) metric with a pre-trained Word2Vec model (GoogleNews).  \n",
        "We also compute distances between the original prompt and each perturbed version.\n",
        "\n",
        "This allows us to evaluate how much meaning is preserved across the perturbed prompts.\n"
      ],
      "metadata": {
        "id": "GTzqkx1SBFix"
      },
      "id": "GTzqkx1SBFix"
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_wmd_scores(model, original: str, gpt_pairs: list) -> list:\n",
        "    \"\"\"Compute safe WMD distances between original output and perturbed outputs.\n",
        "\n",
        "    Args:\n",
        "        model: Word2Vec model.\n",
        "        original (str): Original GPT output.\n",
        "        gpt_pairs (list): List of (perturbed_text, gpt_output).\n",
        "\n",
        "    Returns:\n",
        "        list: List of (perturbed_text, distance).\n",
        "    \"\"\"\n",
        "    scores = []\n",
        "    for text, resp in gpt_pairs:\n",
        "        dist = safe_wmdistance(model, original, resp)\n",
        "        scores.append((text, dist))\n",
        "    return scores\n",
        "\n",
        "\n",
        "def normalize_similarities(wmd_scores: list) -> list:\n",
        "    \"\"\"Normalize distances into similarity scores between 0 and 1.\n",
        "\n",
        "    Args:\n",
        "        wmd_scores (list): List of (text, distance).\n",
        "\n",
        "    Returns:\n",
        "        list: List of (text, similarity).\n",
        "    \"\"\"\n",
        "    values = [d for _, d in wmd_scores]\n",
        "    min_val, max_val = min(values), max(values)\n",
        "    out = []\n",
        "\n",
        "    for text, dist in wmd_scores:\n",
        "        if max_val == min_val:\n",
        "            # All similarities identical when all distances are the same\n",
        "            sim = 1.0\n",
        "        else:\n",
        "            # Convert normalized distance to similarity\n",
        "            sim = 1 - (dist - min_val) / (max_val - min_val)\n",
        "        out.append((text, sim))\n",
        "\n",
        "    for text, sim in out:\n",
        "        logger.info(\"Perturbed Text: %s\", text)\n",
        "        logger.info(\"Similarity Score: %.4f\", sim)\n",
        "        logger.info(\"-\" * 50)\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "RxJKWfA0tSo2"
      },
      "id": "RxJKWfA0tSo2",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"top\"></a>\n",
        "# <div style=\"padding:20px;color:white;margin:0;font-size:35px;font-family:Georgia;text-align:center;display:fill;border-radius:5px;background-color:#003d99;overflow:hidden\"><b>Coefficients and Visual Output of the SMILE Framework</b></div>"
      ],
      "metadata": {
        "id": "WDO9KrvStXNA"
      },
      "id": "WDO9KrvStXNA"
    },
    {
      "cell_type": "markdown",
      "source": [
        "To understand which words in the original prompt most influence the model’s behavior, we fit a weighted linear regression model using the perturbation matrix and normalized similarity scores.\n",
        "\n",
        "The weights are calculated based on the semantic distances (WMD) between perturbed and original outputs, using a Gaussian kernel.\n",
        "\n",
        "The resulting coefficients represent the contribution of each token in the original prompt to the output similarity.\n",
        "\n",
        "We visualize these coefficients as a text-based heatmap, where more influential words are highlighted with stronger colors."
      ],
      "metadata": {
        "id": "TUTWThB4BQPv"
      },
      "id": "TUTWThB4BQPv"
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_weighted_regression(\n",
        "    perturbations: list,\n",
        "    similarities: list,\n",
        "    wmd_scores: list\n",
        ") -> tuple:\n",
        "    \"\"\"Fit weighted linear regression using WMD distances.\n",
        "\n",
        "    Args:\n",
        "        perturbations (list): List of binary perturbation vector\n",
        "            (Perturbations)\n",
        "        similarities (list): List of (text, similarity).\n",
        "        wmd_scores (list): List of (text, distance).\n",
        "\n",
        "    Returns:\n",
        "        tuple: (linear_model, coefficients, weights)\n",
        "    \"\"\"\n",
        "    # Convert Perturbations to a NumPy array\n",
        "    perturb_vecs = np.vstack(perturbations)  # Stack all perturbation vectors vertically\n",
        "\n",
        "    dvals = np.array([d for _, d in wmd_scores])\n",
        "    kernel_w = 0.25\n",
        "    weights = np.sqrt(np.exp(-(dvals ** 2) / (kernel_w ** 2)))\n",
        "\n",
        "    logger.debug(\"Weights:\\n{weights}\", weights)\n",
        "    logger.debug(\"Perturbations:\\n{perturbations}\", perturb_vecs)\n",
        "\n",
        "    y = np.array([s for _, s in similarities])\n",
        "\n",
        "    linear_model = LinearRegression()\n",
        "    linear_model.fit(perturb_vecs, y, sample_weight=weights)\n",
        "\n",
        "    coeffs = linear_model.coef_\n",
        "    logger.info(\"Regression coefficients: %s\", coeffs)\n",
        "\n",
        "    return linear_model, coeffs, weights\n"
      ],
      "metadata": {
        "id": "-ZPAzXlAtY--"
      },
      "id": "-ZPAzXlAtY--",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metrics"
      ],
      "metadata": {
        "id": "uAwhmCvKtbV_"
      },
      "id": "uAwhmCvKtbV_"
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_regression_metrics(\n",
        "    linear_model: LinearRegression,\n",
        "    coeffs: np.ndarray,\n",
        "    weights: np.ndarray,\n",
        "    similarities: list,\n",
        "    perturbations: list\n",
        ") -> dict:\n",
        "    \"\"\"Compute weighted regression metrics.\n",
        "\n",
        "    Args:\n",
        "        linear_model: Trained LinearRegression model.\n",
        "        coeffs (np.ndarray): Regression coefficients.\n",
        "        weights (np.ndarray): Sample weights.\n",
        "        similarities (list): (text, similarity).\n",
        "        perturbations (list): List of binary perturbation vectors.\n",
        "\n",
        "    Returns:\n",
        "        dict: Metrics including weighted R2, L1/L2 losses.\n",
        "    \"\"\"\n",
        "    y_true = np.array([s for _, s in similarities])\n",
        "    y_pred = linear_model.predict(perturbations).ravel()\n",
        "\n",
        "    # Base regression metrics\n",
        "    mse = mean_squared_error(y_true, y_pred, sample_weight=weights)\n",
        "    mae = mean_absolute_error(y_true, y_pred, sample_weight=weights)\n",
        "\n",
        "    # Mean loss\n",
        "    mean_loss = abs(np.mean(y_true) - np.mean(y_pred))\n",
        "\n",
        "    # L1 and L2 losses\n",
        "    diff = y_true - y_pred\n",
        "    mean_l1 = np.mean(np.abs(diff))\n",
        "    mean_l2 = np.mean(diff ** 2)\n",
        "\n",
        "    # Weighted L1 & L2\n",
        "    n = len(y_true)\n",
        "    weighted_l1 = np.sum(weights * np.abs(diff)) / n\n",
        "    weighted_l2 = np.sum(weights * (diff ** 2)) / n\n",
        "\n",
        "    # Weighted R² & Adjusted\n",
        "    p = len(coeffs)\n",
        "    f_mean = np.average(y_true, weights=weights)\n",
        "    ss_tot = np.sum(weights * (y_true - f_mean) ** 2)\n",
        "    ss_res = np.sum(weights * (y_true - y_pred) ** 2)\n",
        "    weighted_r2 = 1 - ss_res / ss_tot\n",
        "\n",
        "    weighted_adj_r2 = 1 - (1 - weighted_r2) * (n - 1) / (n - p - 1)\n",
        "\n",
        "    return {\n",
        "        \"Mean Squared Error (MSE)\": mse,\n",
        "        \"Mean Absolute Error (MAE)\": mae,\n",
        "        \"Mean Loss (Lm)\": mean_loss,\n",
        "        \"Mean L1 Loss\": mean_l1,\n",
        "        \"Mean L2 Loss\": mean_l2,\n",
        "        \"Weighted L1 Loss\": weighted_l1,\n",
        "        \"Weighted L2 Loss\": weighted_l2,\n",
        "        \"Weighted R-squared (R²ω)\": weighted_r2,\n",
        "        \"Weighted Adjusted R-squared (R^²ω)\": weighted_adj_r2,\n",
        "    }\n",
        "\n",
        "\n",
        "def print_metrics(metrics):\n",
        "    print('-' * 100)\n",
        "    print(\"Fidelity:\")\n",
        "    for name, value in metrics.items():\n",
        "        print(f\"{name}: {value}\")\n",
        "    print('-' * 100)\n"
      ],
      "metadata": {
        "id": "Zr5_elSltdG_"
      },
      "id": "Zr5_elSltdG_",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Heatmap visualization"
      ],
      "metadata": {
        "id": "uMmLZv8Ltk0K"
      },
      "id": "uMmLZv8Ltk0K"
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_text_heatmap(\n",
        "    words: list,\n",
        "    scores: np.ndarray,\n",
        "    title: str = \"\",\n",
        "    width: float = 10.0,\n",
        "    height: float = 0.4,\n",
        "    verbose: int = 0,\n",
        "    max_word_per_line: int = 20,\n",
        "    word_spacing: int = 20,\n",
        "    score_fontsize: int = 10,\n",
        "    save_path: str | None = None\n",
        ") -> None:\n",
        "    \"\"\"Plot a heatmap-like visualization over text tokens.\n",
        "\n",
        "    Each token is shown inside a colored box based on its score, with the\n",
        "    numeric score displayed underneath it.\n",
        "\n",
        "    Args:\n",
        "        words (list): List of text tokens.\n",
        "        scores (np.ndarray): Array of per-token scores.\n",
        "        title (str): Title shown on the plot.\n",
        "        width (float): Figure width in inches.\n",
        "        height (float): Figure height in inches.\n",
        "        verbose (int): If 0, hide axes (clean output).\n",
        "        max_word_per_line (int): Max number of tokens per visual line.\n",
        "        word_spacing (int): Horizontal spacing between tokens.\n",
        "        score_fontsize (int): Font size for numeric score labels.\n",
        "        save_path (str | None): Optional save path.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    fig = plt.figure(figsize=(width, height))\n",
        "    ax = plt.gca()\n",
        "    ax.set_title(title, loc=\"left\")\n",
        "\n",
        "    # Color map normalization\n",
        "    cmap = plt.cm.ScalarMappable(cmap=plt.cm.bwr)\n",
        "    cmap.set_clim(0, 1)\n",
        "\n",
        "    denom = np.max(np.abs(scores))\n",
        "    if denom == 0:\n",
        "        denom = 1e-8   # avoid division by zero\n",
        "    normalized = 0.5 * scores / denom + 0.5\n",
        "\n",
        "    canvas = ax.figure.canvas\n",
        "    transform = ax.transData\n",
        "\n",
        "    y = -0.2  # starting y\n",
        "\n",
        "    for i, (word, score, ns) in enumerate(zip(words, scores, normalized)):\n",
        "        r, g, b, _ = cmap.to_rgba(ns, bytes=True)\n",
        "        color = f\"#{r:02x}{g:02x}{b:02x}\"\n",
        "\n",
        "        # draw token\n",
        "        txt = ax.text(\n",
        "            0.0, y, word,\n",
        "            bbox={\n",
        "                \"facecolor\": color,\n",
        "                \"pad\": 5.0,\n",
        "                \"linewidth\": 1,\n",
        "                \"boxstyle\": \"round,pad=0.5\"\n",
        "            },\n",
        "            transform=transform,\n",
        "            fontsize=14\n",
        "        )\n",
        "        txt.draw(canvas.get_renderer())\n",
        "        ex = txt.get_window_extent()\n",
        "\n",
        "        # draw numeric score under token\n",
        "        score_txt = ax.text(\n",
        "            0.01,\n",
        "            y - 1.0,\n",
        "            f\"{score:.2f}\",\n",
        "            transform=transform,\n",
        "            fontsize=score_fontsize,\n",
        "            ha=\"center\"\n",
        "        )\n",
        "        score_txt.draw(canvas.get_renderer())\n",
        "\n",
        "        # new transform for next token\n",
        "        if (i + 1) % max_word_per_line == 0:\n",
        "            y -= 2.5\n",
        "            transform = ax.transData\n",
        "        else:\n",
        "            transform = transforms.offset_copy(\n",
        "                txt._transform,\n",
        "                x=ex.width + word_spacing,\n",
        "                units=\"dots\"\n",
        "            )\n",
        "\n",
        "    if verbose == 0:\n",
        "        ax.axis(\"off\")\n",
        "\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, bbox_inches=\"tight\")\n",
        "\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "FrXVnuJOtlLM"
      },
      "id": "FrXVnuJOtlLM",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# High-level pipeline"
      ],
      "metadata": {
        "id": "hqCEvVSntoHu"
      },
      "id": "hqCEvVSntoHu"
    },
    {
      "cell_type": "code",
      "source": [
        "def run_pipeline(\n",
        "    model: str,\n",
        "    prompt: str,\n",
        "    max_tokens: int = 200,\n",
        "    temperature: float = 0.0,\n",
        "    plot_heatmap: bool = True\n",
        ") -> dict:\n",
        "    \"\"\"Run full GSMILE pipeline from GPT query to regression and metrics.\n",
        "\n",
        "    Args:\n",
        "        model (str): GPT model name.\n",
        "        prompt (str): Original prompt.\n",
        "        max_tokens (int): Max tokens for GPT.\n",
        "        temperature (float): Sampling temperature.\n",
        "        plot_heatmap (bool): Whether to generate heatmap.\n",
        "\n",
        "    Returns:\n",
        "        dict: Results including WMD scores, similarities, coefficients,\n",
        "            metrics.\n",
        "    \"\"\"\n",
        "    client = OpenAI(\n",
        "        api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
        "    )\n",
        "\n",
        "    logger.info(\"Querying GPT for original response...\")\n",
        "    original = gpt_answer(\n",
        "        client, prompt, model, max_tokens, temperature\n",
        "    )\n",
        "\n",
        "    logger.info(\"Generate perturbations...\")\n",
        "    responses, perturbations = generate_perturbations(text=prompt)\n",
        "\n",
        "    logger.info(\"Querying GPT for perturbations...\")\n",
        "    gpt_pairs = query_gpt_for_perturbations(\n",
        "        client, model, responses, max_tokens=10, temperature=temperature\n",
        "    )\n",
        "\n",
        "    logger.info(\"Loading Google news Word2Vec model...\")\n",
        "    model_txt = load_google_news_vectors()\n",
        "    # Precompute and cache vector norms to speed up similarity/WMD calculations\n",
        "    model_txt.fill_norms(force=True)\n",
        "\n",
        "    logger.info(\"Computing WMD scores...\")\n",
        "    wmd_scores = compute_wmd_scores(model_txt, original, gpt_pairs)\n",
        "\n",
        "    logger.info(\"Normalizing similarities...\")\n",
        "    sims = normalize_similarities(wmd_scores)\n",
        "\n",
        "    logger.info(\"Fitting regression model...\")\n",
        "    linear_model, coeffs, weights = fit_weighted_regression(\n",
        "        perturbations, sims, wmd_scores\n",
        "    )\n",
        "\n",
        "    logger.info(\"Computing metrics...\")\n",
        "    metrics = compute_regression_metrics(\n",
        "        linear_model=linear_model,\n",
        "        coeffs=coeffs,\n",
        "        weights=weights,\n",
        "        similarities=sims,\n",
        "        perturbations=perturbations,\n",
        "    )\n",
        "\n",
        "    if plot_heatmap:\n",
        "        logger.info(\"Plotting heatmap...\")\n",
        "        words = prompt.split()\n",
        "        plot_text_heatmap(words, coeffs, \"Text Heatmap\")\n",
        "\n",
        "    return {\n",
        "        \"original_output\": original,\n",
        "        \"gpt_pairs\": gpt_pairs,\n",
        "        \"wmd_scores\": wmd_scores,\n",
        "        \"similarities\": sims,\n",
        "        \"coefficients\": coeffs,\n",
        "        \"weights\": weights,\n",
        "        \"metrics\": metrics\n",
        "    }\n"
      ],
      "metadata": {
        "id": "zLeHDypStpug"
      },
      "id": "zLeHDypStpug",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run pipeline"
      ],
      "metadata": {
        "id": "0zY7cyngtvgJ"
      },
      "id": "0zY7cyngtvgJ"
    },
    {
      "cell_type": "code",
      "source": [
        "result = run_pipeline(\n",
        "    model=\"gpt-3.5-turbo-instruct\",\n",
        "    prompt=\"What is the meaning of life?\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FkTgMUgetyEM",
        "outputId": "a910d1a5-10ed-4aa9-d46e-641f392df232"
      },
      "id": "FkTgMUgetyEM",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:Querying GPT for original response...\n",
            "INFO:__main__:Generate perturbations...\n",
            "INFO:__main__:Perturbation: (np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(0)), Perturbed Text: meaning of\n",
            "INFO:__main__:Perturbation: (np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(1), np.int64(0)), Perturbed Text: What is the of\n",
            "INFO:__main__:Perturbation: (np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(1)), Perturbed Text: What life? the of\n",
            "INFO:__main__:Perturbation: (np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(0)), Perturbed Text: is the meaning\n",
            "INFO:__main__:Perturbation: (np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1)), Perturbed Text: What life?\n",
            "INFO:__main__:Perturbation: (np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1)), Perturbed Text: the life? of is What meaning\n",
            "INFO:__main__:Perturbation: (np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(0)), Perturbed Text: the\n",
            "INFO:__main__:Perturbation: (np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(1)), Perturbed Text: is life?\n",
            "INFO:__main__:Perturbation: (np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(1)), Perturbed Text: life? What is of\n",
            "INFO:__main__:Perturbation: (np.int64(1), np.int64(1), np.int64(0), np.int64(1), np.int64(1), np.int64(1)), Perturbed Text: life? of is What meaning\n",
            "INFO:__main__:Perturbation: (np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(1)), Perturbed Text: What life? of\n",
            "INFO:__main__:Perturbation: (np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0)), Perturbed Text: What is the\n",
            "INFO:__main__:Perturbation: (np.int64(0), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(1)), Perturbed Text: is the life?\n",
            "INFO:__main__:Perturbation: (np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(1)), Perturbed Text: life? the of\n",
            "INFO:__main__:Perturbation: (np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(0)), Perturbed Text: What is the meaning\n",
            "INFO:__main__:Perturbation: (np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(0)), Perturbed Text: What meaning\n",
            "INFO:__main__:Perturbation: (np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(0)), Perturbed Text: What of\n",
            "INFO:__main__:Perturbation: (np.int64(0), np.int64(1), np.int64(1), np.int64(0), np.int64(1), np.int64(1)), Perturbed Text: life? is the of\n",
            "INFO:__main__:Perturbation: (np.int64(0), np.int64(1), np.int64(1), np.int64(0), np.int64(1), np.int64(0)), Perturbed Text: is the of\n",
            "INFO:__main__:Perturbation: (np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(0)), Perturbed Text: is the meaning of\n",
            "INFO:__main__:Perturbation: (np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(1)), Perturbed Text: life? meaning of\n",
            "INFO:__main__:Perturbation: (np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(0)), Perturbed Text: What is of\n",
            "INFO:__main__:Perturbation: (np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(1), np.int64(1)), Perturbed Text: the life? of is What\n",
            "INFO:__main__:Perturbation: (np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(1)), Perturbed Text: What is life?\n",
            "INFO:__main__:Perturbation: (np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(0)), Perturbed Text: meaning\n",
            "INFO:__main__:Perturbation: (np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(0)), Perturbed Text: is of\n",
            "INFO:__main__:Perturbation: (np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(0), np.int64(0)), Perturbed Text: the meaning\n",
            "INFO:__main__:Perturbation: (np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(1)), Perturbed Text: meaning life?\n",
            "INFO:__main__:Perturbation: (np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1)), Perturbed Text: What life?\n",
            "INFO:__main__:Perturbation: (np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(1)), Perturbed Text: What the life?\n",
            "INFO:__main__:Perturbation: (np.int64(1), np.int64(1), np.int64(0), np.int64(1), np.int64(1), np.int64(0)), Perturbed Text: What is meaning of\n",
            "INFO:__main__:Perturbation: (np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1)), Perturbed Text: the life? of is meaning\n",
            "INFO:__main__:Perturbation: (np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(0)), Perturbed Text: What the of\n",
            "INFO:__main__:Perturbation: (np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(1)), Perturbed Text: is meaning life?\n",
            "INFO:__main__:Perturbation: (np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(0)), Perturbed Text: of\n",
            "INFO:__main__:Perturbation: (np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(0)), Perturbed Text: What the\n",
            "INFO:__main__:Perturbation: (np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(0), np.int64(1)), Perturbed Text: the meaning life?\n",
            "INFO:__main__:Perturbation: (np.int64(0), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0)), Perturbed Text: is the\n",
            "INFO:__main__:Perturbation: (np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(0)), Perturbed Text: the of\n",
            "INFO:__main__:Perturbation: (np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(1)), Perturbed Text: life? the meaning of\n",
            "INFO:__main__:Perturbation: (np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(0)), Perturbed Text: the meaning of\n",
            "INFO:__main__:Perturbation: (np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(1)), Perturbed Text: life? of\n",
            "INFO:__main__:Perturbation: (np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(0)), Perturbed Text: is meaning\n",
            "INFO:__main__:Perturbation: (np.int64(1), np.int64(0), np.int64(1), np.int64(1), np.int64(0), np.int64(0)), Perturbed Text: What the meaning\n",
            "INFO:__main__:Perturbation: (np.int64(1), np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(1)), Perturbed Text: the life? of What meaning\n",
            "INFO:__main__:Perturbation: (np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(1), np.int64(0)), Perturbed Text: is meaning of\n",
            "INFO:__main__:Perturbation: (np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0)), Perturbed Text: is meaning\n",
            "INFO:__main__:Perturbation: (np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(1)), Perturbed Text: What is the life?\n",
            "INFO:__main__:Perturbation: (np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(1)), Perturbed Text: the life?\n",
            "INFO:__main__:Perturbation: (np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(1)), Perturbed Text: life? is of\n",
            "INFO:__main__:Perturbation: (np.int64(1), np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(1)), Perturbed Text: What is meaning life?\n",
            "INFO:__main__:Perturbation: (np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0)), Perturbed Text: What is\n",
            "INFO:__main__:Perturbation: (np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(1)), Perturbed Text: is the meaning life?\n",
            "INFO:__main__:Perturbation: (np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(1), np.int64(1)), Perturbed Text: life? is meaning of\n",
            "INFO:__main__:Perturbation: (np.int64(1), np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(0)), Perturbed Text: What the meaning of\n",
            "INFO:__main__:Perturbation: (np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(1)), Perturbed Text: the life? is What meaning\n",
            "INFO:__main__:Perturbation: (np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(0)), Perturbed Text: the of is What meaning\n",
            "INFO:__main__:Perturbation: (np.int64(1), np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(0)), Perturbed Text: What is meaning\n",
            "INFO:__main__:Perturbation: (np.int64(1), np.int64(0), np.int64(1), np.int64(1), np.int64(0), np.int64(1)), Perturbed Text: What the meaning life?\n",
            "INFO:__main__:Perturbation: (np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(1)), Perturbed Text: What meaning life?\n",
            "INFO:__main__:Perturbation: (np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(1)), Perturbed Text: What life? meaning of\n",
            "INFO:__main__:Perturbation: (np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(0)), Perturbed Text: What meaning of\n",
            "INFO:__main__:Perturbation: (np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0)), Perturbed Text: What is\n",
            "INFO:__main__:Perturbation (reused): [1 1 1 0 1 0], Perturbed Text: What is the of\n",
            "INFO:__main__:Querying GPT for perturbations...\n",
            "INFO:__main__:Querying GPT with perturbed text: meaning of\n",
            "INFO:__main__:Querying GPT with perturbed text: What is the of\n",
            "INFO:__main__:Querying GPT with perturbed text: What life? the of\n",
            "INFO:__main__:Querying GPT with perturbed text: is the meaning\n",
            "INFO:__main__:Querying GPT with perturbed text: What life?\n",
            "INFO:__main__:Querying GPT with perturbed text: the life? of is What meaning\n",
            "INFO:__main__:Querying GPT with perturbed text: the\n",
            "INFO:__main__:Querying GPT with perturbed text: is life?\n",
            "INFO:__main__:Querying GPT with perturbed text: life? What is of\n",
            "INFO:__main__:Querying GPT with perturbed text: life? of is What meaning\n",
            "INFO:__main__:Querying GPT with perturbed text: What life? of\n",
            "INFO:__main__:Querying GPT with perturbed text: What is the\n",
            "INFO:__main__:Querying GPT with perturbed text: is the life?\n",
            "INFO:__main__:Querying GPT with perturbed text: life? the of\n",
            "INFO:__main__:Querying GPT with perturbed text: What is the meaning\n",
            "INFO:__main__:Querying GPT with perturbed text: What meaning\n",
            "INFO:__main__:Querying GPT with perturbed text: What of\n",
            "INFO:__main__:Querying GPT with perturbed text: life? is the of\n",
            "INFO:__main__:Querying GPT with perturbed text: is the of\n",
            "INFO:__main__:Querying GPT with perturbed text: is the meaning of\n",
            "INFO:__main__:Querying GPT with perturbed text: life? meaning of\n",
            "INFO:__main__:Querying GPT with perturbed text: What is of\n",
            "INFO:__main__:Querying GPT with perturbed text: the life? of is What\n",
            "INFO:__main__:Querying GPT with perturbed text: What is life?\n",
            "INFO:__main__:Querying GPT with perturbed text: meaning\n",
            "INFO:__main__:Querying GPT with perturbed text: is of\n",
            "INFO:__main__:Querying GPT with perturbed text: the meaning\n",
            "INFO:__main__:Querying GPT with perturbed text: meaning life?\n",
            "INFO:__main__:Querying GPT with perturbed text: What life?\n",
            "INFO:__main__:Querying GPT with perturbed text: What the life?\n",
            "INFO:__main__:Querying GPT with perturbed text: What is meaning of\n",
            "INFO:__main__:Querying GPT with perturbed text: the life? of is meaning\n",
            "INFO:__main__:Querying GPT with perturbed text: What the of\n",
            "INFO:__main__:Querying GPT with perturbed text: is meaning life?\n",
            "INFO:__main__:Querying GPT with perturbed text: of\n",
            "INFO:__main__:Querying GPT with perturbed text: What the\n",
            "INFO:__main__:Querying GPT with perturbed text: the meaning life?\n",
            "INFO:__main__:Querying GPT with perturbed text: is the\n",
            "INFO:__main__:Querying GPT with perturbed text: the of\n",
            "INFO:__main__:Querying GPT with perturbed text: life? the meaning of\n",
            "INFO:__main__:Querying GPT with perturbed text: the meaning of\n",
            "INFO:__main__:Querying GPT with perturbed text: life? of\n",
            "INFO:__main__:Querying GPT with perturbed text: is meaning\n",
            "INFO:__main__:Querying GPT with perturbed text: What the meaning\n",
            "INFO:__main__:Querying GPT with perturbed text: the life? of What meaning\n",
            "INFO:__main__:Querying GPT with perturbed text: is meaning of\n",
            "INFO:__main__:Querying GPT with perturbed text: is meaning\n",
            "INFO:__main__:Querying GPT with perturbed text: What is the life?\n",
            "INFO:__main__:Querying GPT with perturbed text: the life?\n",
            "INFO:__main__:Querying GPT with perturbed text: life? is of\n",
            "INFO:__main__:Querying GPT with perturbed text: What is meaning life?\n",
            "INFO:__main__:Querying GPT with perturbed text: What is\n",
            "INFO:__main__:Querying GPT with perturbed text: is the meaning life?\n",
            "INFO:__main__:Querying GPT with perturbed text: life? is meaning of\n",
            "INFO:__main__:Querying GPT with perturbed text: What the meaning of\n",
            "INFO:__main__:Querying GPT with perturbed text: the life? is What meaning\n",
            "INFO:__main__:Querying GPT with perturbed text: the of is What meaning\n",
            "INFO:__main__:Querying GPT with perturbed text: What is meaning\n",
            "INFO:__main__:Querying GPT with perturbed text: What the meaning life?\n",
            "INFO:__main__:Querying GPT with perturbed text: What meaning life?\n",
            "INFO:__main__:Querying GPT with perturbed text: What life? meaning of\n",
            "INFO:__main__:Querying GPT with perturbed text: What meaning of\n",
            "INFO:__main__:Querying GPT with perturbed text: What is\n",
            "INFO:__main__:Querying GPT with perturbed text: What is the of\n",
            "INFO:__main__:Perturbation 1:\n",
            "INFO:__main__:Input: meaning of\n",
            "INFO:__main__:GPT Output: I am an AI and do not have the\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 2:\n",
            "INFO:__main__:Input: What is the of\n",
            "INFO:__main__:GPT Output: I'm sorry, I cannot provide a number\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 3:\n",
            "INFO:__main__:Input: What life? the of\n",
            "INFO:__main__:GPT Output: 42\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 4:\n",
            "INFO:__main__:Input: is the meaning\n",
            "INFO:__main__:GPT Output: I'm sorry, I cannot provide a single\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 5:\n",
            "INFO:__main__:Input: What life?\n",
            "INFO:__main__:GPT Output: 42\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 6:\n",
            "INFO:__main__:Input: the life? of is What meaning\n",
            "INFO:__main__:GPT Output: 42\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 7:\n",
            "INFO:__main__:Input: the\n",
            "INFO:__main__:GPT Output: 42\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 8:\n",
            "INFO:__main__:Input: is life?\n",
            "INFO:__main__:GPT Output: 42\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 9:\n",
            "INFO:__main__:Input: life? What is of\n",
            "INFO:__main__:GPT Output: 42\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 10:\n",
            "INFO:__main__:Input: life? of is What meaning\n",
            "INFO:__main__:GPT Output: 42\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 11:\n",
            "INFO:__main__:Input: What life? of\n",
            "INFO:__main__:GPT Output: 42\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 12:\n",
            "INFO:__main__:Input: What is the\n",
            "INFO:__main__:GPT Output: I am an AI and I do not have\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 13:\n",
            "INFO:__main__:Input: is the life?\n",
            "INFO:__main__:GPT Output: 42\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 14:\n",
            "INFO:__main__:Input: life? the of\n",
            "INFO:__main__:GPT Output: 42\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 15:\n",
            "INFO:__main__:Input: What is the meaning\n",
            "INFO:__main__:GPT Output: I'm sorry, I am an AI and\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 16:\n",
            "INFO:__main__:Input: What meaning\n",
            "INFO:__main__:GPT Output: 42\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 17:\n",
            "INFO:__main__:Input: What of\n",
            "INFO:__main__:GPT Output: I cannot provide a number without context. Please\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 18:\n",
            "INFO:__main__:Input: life? is the of\n",
            "INFO:__main__:GPT Output: 42\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 19:\n",
            "INFO:__main__:Input: is the of\n",
            "INFO:__main__:GPT Output: 42\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 20:\n",
            "INFO:__main__:Input: is the meaning of\n",
            "INFO:__main__:GPT Output: I'm sorry, I cannot provide a response\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 21:\n",
            "INFO:__main__:Input: life? meaning of\n",
            "INFO:__main__:GPT Output: 42\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 22:\n",
            "INFO:__main__:Input: What is of\n",
            "INFO:__main__:GPT Output: I am an AI and do not have a\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 23:\n",
            "INFO:__main__:Input: the life? of is What\n",
            "INFO:__main__:GPT Output: 42\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 24:\n",
            "INFO:__main__:Input: What is life?\n",
            "INFO:__main__:GPT Output: 42\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 25:\n",
            "INFO:__main__:Input: meaning\n",
            "INFO:__main__:GPT Output: 42\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 26:\n",
            "INFO:__main__:Input: is of\n",
            "INFO:__main__:GPT Output: 42\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 27:\n",
            "INFO:__main__:Input: the meaning\n",
            "INFO:__main__:GPT Output: I'm sorry, I cannot provide a single\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 28:\n",
            "INFO:__main__:Input: meaning life?\n",
            "INFO:__main__:GPT Output: 42\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 29:\n",
            "INFO:__main__:Input: What life?\n",
            "INFO:__main__:GPT Output: 42\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 30:\n",
            "INFO:__main__:Input: What the life?\n",
            "INFO:__main__:GPT Output: 42\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 31:\n",
            "INFO:__main__:Input: What is meaning of\n",
            "INFO:__main__:GPT Output: This statement is asking for a numerical response without\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 32:\n",
            "INFO:__main__:Input: the life? of is meaning\n",
            "INFO:__main__:GPT Output: 42\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 33:\n",
            "INFO:__main__:Input: What the of\n",
            "INFO:__main__:GPT Output: I am an AI and I do not have\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 34:\n",
            "INFO:__main__:Input: is meaning life?\n",
            "INFO:__main__:GPT Output: 42\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 35:\n",
            "INFO:__main__:Input: of\n",
            "INFO:__main__:GPT Output: 42\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 36:\n",
            "INFO:__main__:Input: What the\n",
            "INFO:__main__:GPT Output: 42\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 37:\n",
            "INFO:__main__:Input: the meaning life?\n",
            "INFO:__main__:GPT Output: 42\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 38:\n",
            "INFO:__main__:Input: is the\n",
            "INFO:__main__:GPT Output: 42\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 39:\n",
            "INFO:__main__:Input: the of\n",
            "INFO:__main__:GPT Output: 42\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 40:\n",
            "INFO:__main__:Input: life? the meaning of\n",
            "INFO:__main__:GPT Output: 42\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 41:\n",
            "INFO:__main__:Input: the meaning of\n",
            "INFO:__main__:GPT Output: 42\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 42:\n",
            "INFO:__main__:Input: life? of\n",
            "INFO:__main__:GPT Output: 42\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 43:\n",
            "INFO:__main__:Input: is meaning\n",
            "INFO:__main__:GPT Output: 3\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 44:\n",
            "INFO:__main__:Input: What the meaning\n",
            "INFO:__main__:GPT Output: I'm sorry, I cannot provide a single\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 45:\n",
            "INFO:__main__:Input: the life? of What meaning\n",
            "INFO:__main__:GPT Output: 42\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 46:\n",
            "INFO:__main__:Input: is meaning of\n",
            "INFO:__main__:GPT Output: I'm sorry, I cannot provide a response\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 47:\n",
            "INFO:__main__:Input: is meaning\n",
            "INFO:__main__:GPT Output: 3\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 48:\n",
            "INFO:__main__:Input: What is the life?\n",
            "INFO:__main__:GPT Output: I'm sorry, I cannot provide a single\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 49:\n",
            "INFO:__main__:Input: the life?\n",
            "INFO:__main__:GPT Output: 42\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 50:\n",
            "INFO:__main__:Input: life? is of\n",
            "INFO:__main__:GPT Output: 42\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 51:\n",
            "INFO:__main__:Input: What is meaning life?\n",
            "INFO:__main__:GPT Output: 42\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 52:\n",
            "INFO:__main__:Input: What is\n",
            "INFO:__main__:GPT Output: I am an AI and do not have the\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 53:\n",
            "INFO:__main__:Input: is the meaning life?\n",
            "INFO:__main__:GPT Output: 42\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 54:\n",
            "INFO:__main__:Input: life? is meaning of\n",
            "INFO:__main__:GPT Output: 42\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 55:\n",
            "INFO:__main__:Input: What the meaning of\n",
            "INFO:__main__:GPT Output: I'm sorry, I cannot provide a response\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 56:\n",
            "INFO:__main__:Input: the life? is What meaning\n",
            "INFO:__main__:GPT Output: 42\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 57:\n",
            "INFO:__main__:Input: the of is What meaning\n",
            "INFO:__main__:GPT Output: 42\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 58:\n",
            "INFO:__main__:Input: What is meaning\n",
            "INFO:__main__:GPT Output: I'm sorry, I cannot provide a single\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 59:\n",
            "INFO:__main__:Input: What the meaning life?\n",
            "INFO:__main__:GPT Output: 42\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 60:\n",
            "INFO:__main__:Input: What meaning life?\n",
            "INFO:__main__:GPT Output: 42\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 61:\n",
            "INFO:__main__:Input: What life? meaning of\n",
            "INFO:__main__:GPT Output: 42\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 62:\n",
            "INFO:__main__:Input: What meaning of\n",
            "INFO:__main__:GPT Output: This means to provide a numerical answer without any\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 63:\n",
            "INFO:__main__:Input: What is\n",
            "INFO:__main__:GPT Output: I am an AI and do not have the\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbation 64:\n",
            "INFO:__main__:Input: What is the of\n",
            "INFO:__main__:GPT Output: I'm sorry, I cannot provide a number\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Loading Google news Word2Vec model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trying to load 'word2vec-google-news-300' via gensim.api...\n",
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:Computing WMD scores...\n",
            "INFO:__main__:Normalizing similarities...\n",
            "INFO:__main__:Perturbed Text: meaning of\n",
            "INFO:__main__:Similarity Score: 0.6926\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: What is the of\n",
            "INFO:__main__:Similarity Score: 0.3423\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: What life? the of\n",
            "INFO:__main__:Similarity Score: 1.0000\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: is the meaning\n",
            "INFO:__main__:Similarity Score: 0.3327\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: What life?\n",
            "INFO:__main__:Similarity Score: 1.0000\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: the life? of is What meaning\n",
            "INFO:__main__:Similarity Score: 1.0000\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: the\n",
            "INFO:__main__:Similarity Score: 1.0000\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: is life?\n",
            "INFO:__main__:Similarity Score: 1.0000\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: life? What is of\n",
            "INFO:__main__:Similarity Score: 1.0000\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: life? of is What meaning\n",
            "INFO:__main__:Similarity Score: 1.0000\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: What life? of\n",
            "INFO:__main__:Similarity Score: 1.0000\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: What is the\n",
            "INFO:__main__:Similarity Score: 0.5098\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: is the life?\n",
            "INFO:__main__:Similarity Score: 1.0000\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: life? the of\n",
            "INFO:__main__:Similarity Score: 1.0000\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: What is the meaning\n",
            "INFO:__main__:Similarity Score: 0.2628\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: What meaning\n",
            "INFO:__main__:Similarity Score: 1.0000\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: What of\n",
            "INFO:__main__:Similarity Score: 0.4053\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: life? is the of\n",
            "INFO:__main__:Similarity Score: 1.0000\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: is the of\n",
            "INFO:__main__:Similarity Score: 1.0000\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: is the meaning of\n",
            "INFO:__main__:Similarity Score: 0.3013\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: life? meaning of\n",
            "INFO:__main__:Similarity Score: 1.0000\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: What is of\n",
            "INFO:__main__:Similarity Score: 0.5332\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: the life? of is What\n",
            "INFO:__main__:Similarity Score: 1.0000\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: What is life?\n",
            "INFO:__main__:Similarity Score: 1.0000\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: meaning\n",
            "INFO:__main__:Similarity Score: 1.0000\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: is of\n",
            "INFO:__main__:Similarity Score: 1.0000\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: the meaning\n",
            "INFO:__main__:Similarity Score: 0.3327\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: meaning life?\n",
            "INFO:__main__:Similarity Score: 1.0000\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: What life?\n",
            "INFO:__main__:Similarity Score: 1.0000\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: What the life?\n",
            "INFO:__main__:Similarity Score: 1.0000\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: What is meaning of\n",
            "INFO:__main__:Similarity Score: 0.6975\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: the life? of is meaning\n",
            "INFO:__main__:Similarity Score: 1.0000\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: What the of\n",
            "INFO:__main__:Similarity Score: 0.5098\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: is meaning life?\n",
            "INFO:__main__:Similarity Score: 1.0000\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: of\n",
            "INFO:__main__:Similarity Score: 1.0000\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: What the\n",
            "INFO:__main__:Similarity Score: 1.0000\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: the meaning life?\n",
            "INFO:__main__:Similarity Score: 1.0000\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: is the\n",
            "INFO:__main__:Similarity Score: 1.0000\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: the of\n",
            "INFO:__main__:Similarity Score: 1.0000\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: life? the meaning of\n",
            "INFO:__main__:Similarity Score: 1.0000\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: the meaning of\n",
            "INFO:__main__:Similarity Score: 1.0000\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: life? of\n",
            "INFO:__main__:Similarity Score: 1.0000\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: is meaning\n",
            "INFO:__main__:Similarity Score: 0.0000\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: What the meaning\n",
            "INFO:__main__:Similarity Score: 0.3327\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: the life? of What meaning\n",
            "INFO:__main__:Similarity Score: 1.0000\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: is meaning of\n",
            "INFO:__main__:Similarity Score: 0.3013\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: is meaning\n",
            "INFO:__main__:Similarity Score: 0.0000\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: What is the life?\n",
            "INFO:__main__:Similarity Score: 0.3327\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: the life?\n",
            "INFO:__main__:Similarity Score: 1.0000\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: life? is of\n",
            "INFO:__main__:Similarity Score: 1.0000\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: What is meaning life?\n",
            "INFO:__main__:Similarity Score: 1.0000\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: What is\n",
            "INFO:__main__:Similarity Score: 0.6926\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: is the meaning life?\n",
            "INFO:__main__:Similarity Score: 1.0000\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: life? is meaning of\n",
            "INFO:__main__:Similarity Score: 1.0000\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: What the meaning of\n",
            "INFO:__main__:Similarity Score: 0.3013\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: the life? is What meaning\n",
            "INFO:__main__:Similarity Score: 1.0000\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: the of is What meaning\n",
            "INFO:__main__:Similarity Score: 1.0000\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: What is meaning\n",
            "INFO:__main__:Similarity Score: 0.3327\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: What the meaning life?\n",
            "INFO:__main__:Similarity Score: 1.0000\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: What meaning life?\n",
            "INFO:__main__:Similarity Score: 1.0000\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: What life? meaning of\n",
            "INFO:__main__:Similarity Score: 1.0000\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: What meaning of\n",
            "INFO:__main__:Similarity Score: 0.5901\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: What is\n",
            "INFO:__main__:Similarity Score: 0.6926\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Perturbed Text: What is the of\n",
            "INFO:__main__:Similarity Score: 0.3423\n",
            "INFO:__main__:--------------------------------------------------\n",
            "INFO:__main__:Fitting regression model...\n",
            "INFO:__main__:Regression coefficients: [-0.0156223  -0.00516307  0.0098198  -0.00151779 -0.00145014  0.03246633]\n",
            "INFO:__main__:Computing metrics...\n",
            "INFO:__main__:Plotting heatmap...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x40 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvhOnxc67LrE",
        "outputId": "90801451-0ddb-4f27-cb6a-b73d670b07b2"
      },
      "id": "ZvhOnxc67LrE",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'original_output': 'The meaning of life is a philosophical question that has been debated by many thinkers and scholars throughout history. It is a complex and subjective concept that can have different interpretations and meanings for different individuals. Some believe that the meaning of life is to find happiness and fulfillment, while others believe it is to fulfill a certain purpose or destiny. Some see it as a journey of self-discovery and personal growth, while others see it as a way to contribute to the greater good of society. Ultimately, the meaning of life is a deeply personal and individual concept that can vary greatly from person to person.',\n",
              " 'gpt_pairs': [('meaning of', 'I am an AI and do not have the'),\n",
              "  ('What is the of', \"I'm sorry, I cannot provide a number\"),\n",
              "  ('What life? the of', '42'),\n",
              "  ('is the meaning', \"I'm sorry, I cannot provide a single\"),\n",
              "  ('What life?', '42'),\n",
              "  ('the life? of is What meaning', '42'),\n",
              "  ('the', '42'),\n",
              "  ('is life?', '42'),\n",
              "  ('life? What is of', '42'),\n",
              "  ('life? of is What meaning', '42'),\n",
              "  ('What life? of', '42'),\n",
              "  ('What is the', 'I am an AI and I do not have'),\n",
              "  ('is the life?', '42'),\n",
              "  ('life? the of', '42'),\n",
              "  ('What is the meaning', \"I'm sorry, I am an AI and\"),\n",
              "  ('What meaning', '42'),\n",
              "  ('What of', 'I cannot provide a number without context. Please'),\n",
              "  ('life? is the of', '42'),\n",
              "  ('is the of', '42'),\n",
              "  ('is the meaning of', \"I'm sorry, I cannot provide a response\"),\n",
              "  ('life? meaning of', '42'),\n",
              "  ('What is of', 'I am an AI and do not have a'),\n",
              "  ('the life? of is What', '42'),\n",
              "  ('What is life?', '42'),\n",
              "  ('meaning', '42'),\n",
              "  ('is of', '42'),\n",
              "  ('the meaning', \"I'm sorry, I cannot provide a single\"),\n",
              "  ('meaning life?', '42'),\n",
              "  ('What life?', '42'),\n",
              "  ('What the life?', '42'),\n",
              "  ('What is meaning of',\n",
              "   'This statement is asking for a numerical response without'),\n",
              "  ('the life? of is meaning', '42'),\n",
              "  ('What the of', 'I am an AI and I do not have'),\n",
              "  ('is meaning life?', '42'),\n",
              "  ('of', '42'),\n",
              "  ('What the', '42'),\n",
              "  ('the meaning life?', '42'),\n",
              "  ('is the', '42'),\n",
              "  ('the of', '42'),\n",
              "  ('life? the meaning of', '42'),\n",
              "  ('the meaning of', '42'),\n",
              "  ('life? of', '42'),\n",
              "  ('is meaning', '3'),\n",
              "  ('What the meaning', \"I'm sorry, I cannot provide a single\"),\n",
              "  ('the life? of What meaning', '42'),\n",
              "  ('is meaning of', \"I'm sorry, I cannot provide a response\"),\n",
              "  ('is meaning', '3'),\n",
              "  ('What is the life?', \"I'm sorry, I cannot provide a single\"),\n",
              "  ('the life?', '42'),\n",
              "  ('life? is of', '42'),\n",
              "  ('What is meaning life?', '42'),\n",
              "  ('What is', 'I am an AI and do not have the'),\n",
              "  ('is the meaning life?', '42'),\n",
              "  ('life? is meaning of', '42'),\n",
              "  ('What the meaning of', \"I'm sorry, I cannot provide a response\"),\n",
              "  ('the life? is What meaning', '42'),\n",
              "  ('the of is What meaning', '42'),\n",
              "  ('What is meaning', \"I'm sorry, I cannot provide a single\"),\n",
              "  ('What the meaning life?', '42'),\n",
              "  ('What meaning life?', '42'),\n",
              "  ('What life? meaning of', '42'),\n",
              "  ('What meaning of', 'This means to provide a numerical answer without any'),\n",
              "  ('What is', 'I am an AI and do not have the'),\n",
              "  ('What is the of', \"I'm sorry, I cannot provide a number\")],\n",
              " 'wmd_scores': [('meaning of', 1.1168624920791228),\n",
              "  ('What is the of', 1.250071978175422),\n",
              "  ('What life? the of', 1.0),\n",
              "  ('is the meaning', 1.2537268096111513),\n",
              "  ('What life?', 1.0),\n",
              "  ('the life? of is What meaning', 1.0),\n",
              "  ('the', 1.0),\n",
              "  ('is life?', 1.0),\n",
              "  ('life? What is of', 1.0),\n",
              "  ('life? of is What meaning', 1.0),\n",
              "  ('What life? of', 1.0),\n",
              "  ('What is the', 1.18639193023658),\n",
              "  ('is the life?', 1.0),\n",
              "  ('life? the of', 1.0),\n",
              "  ('What is the meaning', 1.280317944530996),\n",
              "  ('What meaning', 1.0),\n",
              "  ('What of', 1.2260996361933447),\n",
              "  ('life? is the of', 1.0),\n",
              "  ('is the of', 1.0),\n",
              "  ('is the meaning of', 1.2656655758487574),\n",
              "  ('life? meaning of', 1.0),\n",
              "  ('What is of', 1.1774703468350618),\n",
              "  ('the life? of is What', 1.0),\n",
              "  ('What is life?', 1.0),\n",
              "  ('meaning', 1.0),\n",
              "  ('is of', 1.0),\n",
              "  ('the meaning', 1.2537268096111513),\n",
              "  ('meaning life?', 1.0),\n",
              "  ('What life?', 1.0),\n",
              "  ('What the life?', 1.0),\n",
              "  ('What is meaning of', 1.1150274132433853),\n",
              "  ('the life? of is meaning', 1.0),\n",
              "  ('What the of', 1.18639193023658),\n",
              "  ('is meaning life?', 1.0),\n",
              "  ('of', 1.0),\n",
              "  ('What the', 1.0),\n",
              "  ('the meaning life?', 1.0),\n",
              "  ('is the', 1.0),\n",
              "  ('the of', 1.0),\n",
              "  ('life? the meaning of', 1.0),\n",
              "  ('the meaning of', 1.0),\n",
              "  ('life? of', 1.0),\n",
              "  ('is meaning', 1.3802219486016571),\n",
              "  ('What the meaning', 1.2537268096111513),\n",
              "  ('the life? of What meaning', 1.0),\n",
              "  ('is meaning of', 1.2656655758487574),\n",
              "  ('is meaning', 1.3802219486016571),\n",
              "  ('What is the life?', 1.2537268096111513),\n",
              "  ('the life?', 1.0),\n",
              "  ('life? is of', 1.0),\n",
              "  ('What is meaning life?', 1.0),\n",
              "  ('What is', 1.1168624920791228),\n",
              "  ('is the meaning life?', 1.0),\n",
              "  ('life? is meaning of', 1.0),\n",
              "  ('What the meaning of', 1.2656655758487574),\n",
              "  ('the life? is What meaning', 1.0),\n",
              "  ('the of is What meaning', 1.0),\n",
              "  ('What is meaning', 1.2537268096111513),\n",
              "  ('What the meaning life?', 1.0),\n",
              "  ('What meaning life?', 1.0),\n",
              "  ('What life? meaning of', 1.0),\n",
              "  ('What meaning of', 1.1558574589852175),\n",
              "  ('What is', 1.1168624920791228),\n",
              "  ('What is the of', 1.250071978175422)],\n",
              " 'similarities': [('meaning of', 0.6926466436014329),\n",
              "  ('What is the of', 0.3422999932141949),\n",
              "  ('What life? the of', 1.0),\n",
              "  ('is the meaning', 0.3326876300953092),\n",
              "  ('What life?', 1.0),\n",
              "  ('the life? of is What meaning', 1.0),\n",
              "  ('the', 1.0),\n",
              "  ('is life?', 1.0),\n",
              "  ('life? What is of', 1.0),\n",
              "  ('life? of is What meaning', 1.0),\n",
              "  ('What life? of', 1.0),\n",
              "  ('What is the', 0.5097812450804751),\n",
              "  ('is the life?', 1.0),\n",
              "  ('life? the of', 1.0),\n",
              "  ('What is the meaning', 0.262751807038174),\n",
              "  ('What meaning', 1.0),\n",
              "  ('What of', 0.40534827874910506),\n",
              "  ('life? is the of', 1.0),\n",
              "  ('is the of', 1.0),\n",
              "  ('is the meaning of', 0.30128816385851453),\n",
              "  ('life? meaning of', 1.0),\n",
              "  ('What is of', 0.533245391309616),\n",
              "  ('the life? of is What', 1.0),\n",
              "  ('What is life?', 1.0),\n",
              "  ('meaning', 1.0),\n",
              "  ('is of', 1.0),\n",
              "  ('the meaning', 0.3326876300953092),\n",
              "  ('meaning life?', 1.0),\n",
              "  ('What life?', 1.0),\n",
              "  ('What the life?', 1.0),\n",
              "  ('What is meaning of', 0.6974729794888965),\n",
              "  ('the life? of is meaning', 1.0),\n",
              "  ('What the of', 0.5097812450804751),\n",
              "  ('is meaning life?', 1.0),\n",
              "  ('of', 1.0),\n",
              "  ('What the', 1.0),\n",
              "  ('the meaning life?', 1.0),\n",
              "  ('is the', 1.0),\n",
              "  ('the of', 1.0),\n",
              "  ('life? the meaning of', 1.0),\n",
              "  ('the meaning of', 1.0),\n",
              "  ('life? of', 1.0),\n",
              "  ('is meaning', 0.0),\n",
              "  ('What the meaning', 0.3326876300953092),\n",
              "  ('the life? of What meaning', 1.0),\n",
              "  ('is meaning of', 0.30128816385851453),\n",
              "  ('is meaning', 0.0),\n",
              "  ('What is the life?', 0.3326876300953092),\n",
              "  ('the life?', 1.0),\n",
              "  ('life? is of', 1.0),\n",
              "  ('What is meaning life?', 1.0),\n",
              "  ('What is', 0.6926466436014329),\n",
              "  ('is the meaning life?', 1.0),\n",
              "  ('life? is meaning of', 1.0),\n",
              "  ('What the meaning of', 0.30128816385851453),\n",
              "  ('the life? is What meaning', 1.0),\n",
              "  ('the of is What meaning', 1.0),\n",
              "  ('What is meaning', 0.3326876300953092),\n",
              "  ('What the meaning life?', 1.0),\n",
              "  ('What meaning life?', 1.0),\n",
              "  ('What life? meaning of', 1.0),\n",
              "  ('What meaning of', 0.5900882114817023),\n",
              "  ('What is', 0.6926466436014329),\n",
              "  ('What is the of', 0.3422999932141949)],\n",
              " 'coefficients': array([-0.0156223 , -0.00516307,  0.0098198 , -0.00151779, -0.00145014,\n",
              "         0.03246633]),\n",
              " 'weights': array([4.63608776e-05, 3.72129212e-06, 3.35462628e-04, 3.45859782e-06,\n",
              "        3.35462628e-04, 3.35462628e-04, 3.35462628e-04, 3.35462628e-04,\n",
              "        3.35462628e-04, 3.35462628e-04, 3.35462628e-04, 1.28752139e-05,\n",
              "        3.35462628e-04, 3.35462628e-04, 2.01737719e-06, 3.35462628e-04,\n",
              "        5.98315497e-06, 3.35462628e-04, 3.35462628e-04, 2.71892276e-06,\n",
              "        3.35462628e-04, 1.52414580e-05, 3.35462628e-04, 3.35462628e-04,\n",
              "        3.35462628e-04, 3.35462628e-04, 3.45859782e-06, 3.35462628e-04,\n",
              "        3.35462628e-04, 3.35462628e-04, 4.79050774e-05, 3.35462628e-04,\n",
              "        1.28752139e-05, 3.35462628e-04, 3.35462628e-04, 3.35462628e-04,\n",
              "        3.35462628e-04, 3.35462628e-04, 3.35462628e-04, 3.35462628e-04,\n",
              "        3.35462628e-04, 3.35462628e-04, 2.40606981e-07, 3.45859782e-06,\n",
              "        3.35462628e-04, 2.71892276e-06, 2.40606981e-07, 3.45859782e-06,\n",
              "        3.35462628e-04, 3.35462628e-04, 3.35462628e-04, 4.63608776e-05,\n",
              "        3.35462628e-04, 3.35462628e-04, 2.71892276e-06, 3.35462628e-04,\n",
              "        3.35462628e-04, 3.45859782e-06, 3.35462628e-04, 3.35462628e-04,\n",
              "        3.35462628e-04, 2.28159268e-05, 4.63608776e-05, 3.72129212e-06]),\n",
              " 'metrics': {'Mean Squared Error (MSE)': 0.0031288578599134326,\n",
              "  'Mean Absolute Error (MAE)': 0.019897211635952747,\n",
              "  'Mean Loss (Lm)': np.float64(0.188874737908862),\n",
              "  'Mean L1 Loss': np.float64(0.20220305466430827),\n",
              "  'Mean L2 Loss': np.float64(0.12267636474032828),\n",
              "  'Weighted L1 Loss': np.float64(4.4711521642990545e-06),\n",
              "  'Weighted L2 Loss': np.float64(7.030934709895687e-07),\n",
              "  'Weighted R-squared (R²ω)': np.float64(0.07330621208583687),\n",
              "  'Weighted Adjusted R-squared (R^²ω)': np.float64(-0.0242405024314436)}}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 📚 References\n",
        "\n",
        "1. **OpenAI.** (2023). *GPT-3.5 and Instruct Models*.  \n",
        "   Retrieved from https://platform.openai.com/docs\n",
        "\n",
        "2. **Kusner, M., Sun, Y., Kolkin, N., & Weinberger, K. Q.** (2015).  \n",
        "   *From Word Embeddings to Document Distances*.  \n",
        "   In *Proceedings of the 32nd International Conference on Machine Learning (ICML)*.  \n",
        "   https://proceedings.mlr.press/v37/kusnerb15.html\n",
        "\n",
        "3. **Mikolov, T., Chen, K., Corrado, G., & Dean, J.** (2013).  \n",
        "   *Efficient Estimation of Word Representations in Vector Space*.  \n",
        "   arXiv:1301.3781 [cs.CL].  \n",
        "   https://code.google.com/archive/p/word2vec/\n",
        "\n",
        "4. **Ribeiro, M. T., Singh, S., & Guestrin, C.** (2016).  \n",
        "   *\"Why Should I Trust You?\": Explaining the Predictions of Any Classifier*.  \n",
        "   In *Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD)*.  \n",
        "   https://doi.org/10.1145/2939672.2939778\n",
        "\n",
        "5. **Aslansefat, K., Hashemian, M., Walker, M., Akram, M. N., Sorokos, I., & Papadopoulos, Y.** (2023).  \n",
        "   *Explaining Black Boxes with a SMILE: Statistical Model-agnostic Interpretability with Local Explanations*.  \n",
        "   *IEEE Software*, 41(1), 87–97.  \n",
        "   https://doi.org/10.1109/MS.2023.10112345\n"
      ],
      "metadata": {
        "id": "yLzIjgG-BZef"
      },
      "id": "yLzIjgG-BZef"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TlkDlctrBZ6r"
      },
      "id": "TlkDlctrBZ6r",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "isSourceIdPinned": true,
          "modelId": 222479,
          "modelInstanceId": 200656,
          "sourceId": 234902,
          "sourceType": "modelInstanceVersion"
        }
      ],
      "dockerImageVersionId": 31040,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 443.037519,
      "end_time": "2025-06-02T17:41:34.207281",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2025-06-02T17:34:11.169762",
      "version": "2.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}